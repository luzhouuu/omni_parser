#!/usr/bin/env python3
"""Wanfang Medical Paper Safety Classification Script.

This script classifies downloaded papers from Wanfang Medical database
using LLM (OpenAI GPT) for pharmacovigilance/drug safety classification.

æ–‡çŒ®æ£€ç´¢ä¸šåŠ¡åŸºç¡€æµç¨‹ï¼š
åœ¨å…¨æ–‡èŒƒå›´å†…ä»¥ä¸­è‹±æ–‡å•†å“å&æ´»æ€§æˆåˆ†åä½œä¸ºå…³é”®è¯è¿›è¡Œæ£€ç´¢ï¼Œæ£€ç´¢å‡ºæœ¬å‘¨æœŸå†…ä¸ŠæŠ›åˆ°
CNKI & Wanfangæ•°æ®åº“ä¸­çš„æ–‡çŒ®ã€‚é’ˆå¯¹æ‰€æœ‰æ£€ç´¢å‡ºæ¥çš„æ–‡çŒ®è¿›è¡Œäººå·¥å®¡é˜…ï¼Œè¯†åˆ«æ–‡ç« ä¸­
æ˜¯å¦æåŠä»»ä½•è¯ºåè¯ç›¸å…³å®‰å…¨ç—…ä¾‹æˆ–æ½œåœ¨ä¿¡å·ã€‚

Classification categories (è¯ç‰©å®‰å…¨åˆ†ç±»):
- Rejection: æ–‡ç« ä¸­ç¼ºå°‘drug(è¯ºåè¯)æˆ–AE(ä¸è‰¯äº‹ä»¶)ä»»æ„ä¸€ä¸ªè¦ç´ 
- ICSR: (drug+AE+å› æœå…³ç³»+å•ä¸ªæ‚£è€…) OR (drug+ç‰¹æ®Šæƒ…å†µ+å•ä¸ªæ‚£è€…)
- Multiple_Patients: (drug+AE+å› æœå…³ç³»+å¤šä¸ªæ‚£è€…) OR (drug+ç‰¹æ®Šæƒ…å†µ+å¤šä¸ªæ‚£è€…)
- ICSR+Multiple_Patients: ä¸€ç¯‡æ–‡ç« åŒæ—¶æ»¡è¶³ICSRå’ŒMultiple_Patientsçš„æ¡ä»¶
- Other_Safety_Signal: ä¸ç¬¦åˆä¸Šé¢ç±»å‹çš„éƒ½åˆç­›æˆsignal

Usage:
    # Classify all papers in data/papers/
    python scripts/wanfang_classify.py --drugs "æ›¿æ ¼ç‘æ´›,ticagrelor"

    # With drug keywords file
    python scripts/wanfang_classify.py --drugs-file data/drug_keywords.txt

    # Specify custom directory
    python scripts/wanfang_classify.py --input-dir data/papers --drugs "è¯ç‰©å"
"""

import argparse
import csv
import json
import os
import subprocess
import tempfile
from dataclasses import dataclass, field, asdict, replace
from datetime import datetime
from pathlib import Path
from typing import Any

from dotenv import load_dotenv
from openai import OpenAI

# Multi-Agent Classification (optional)
try:
    from multi_agent_classify import classify_with_multi_agent, MultiAgentResult
    MULTI_AGENT_AVAILABLE = True
except ImportError:
    MULTI_AGENT_AVAILABLE = False

# Load environment variables
load_dotenv()

# Directories
DATA_DIR = Path(__file__).parent.parent / "data"
PAPERS_DIR = DATA_DIR / "papers"
DEFAULT_OUTPUT = DATA_DIR / "classification_results.csv"
DEFAULT_DRUGS_FILE = DATA_DIR / "novartis_drugs.txt"


# Classification labels
SAFETY_LABELS = {
    "Rejection": "æ‹’ç» (ç¼ºå°‘è¯ç‰©æˆ–AE)",
    "ICSR": "ä¸ªä¾‹å®‰å…¨æŠ¥å‘Š (å•æ‚£è€…)",
    "Multiple_Patients": "å¤šæ‚£è€…æŠ¥å‘Š (>1ä¾‹)",
    "ICSR+Multiple_Patients": "æ··åˆæŠ¥å‘Š (åŒæ—¶æœ‰å•æ‚£è€…å’Œå¤šæ‚£è€…)",
    "Other_Safety_Signal": "å…¶ä»–å®‰å…¨ä¿¡å· (åˆç­›)",
}

PATIENT_MODES = {"single", "multiple", "mixed", "unknown"}


@dataclass
class PatientInfo:
    mode: str  # single / multiple / mixed / unknown
    max_n: int | None
    evidence: list[str]


@dataclass
class ClassificationResult:
    filename: str
    label: str
    label_cn: str
    has_drug: bool
    has_ae: bool
    has_causality: bool
    has_special_situation: bool
    patient_mode: str
    patient_max_n: int | None
    confidence: float
    drug_evidence: list[str]
    ae_evidence: list[str]
    causality_evidence: list[str]
    special_evidence: list[str]
    patient_evidence: list[str]
    # å„å­—æ®µçš„ç‹¬ç«‹ reasoning
    has_drug_reasoning: str
    has_ae_reasoning: str
    has_causality_reasoning: str
    has_special_reasoning: str
    patient_reasoning: str
    reasoning: str
    needs_review: bool
    extract_method: str
    text_length: int
    classify_time: str = field(default_factory=lambda: datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    error: str = ""


def which(cmd: str) -> str | None:
    """Find executable in PATH."""
    import shutil
    return shutil.which(cmd)


def extract_pdf_text(pdf_path: Path, max_pages: int = 30) -> tuple[str, str]:
    """Extract text from PDF using pdftotext or pymupdf."""
    # Try pdftotext first
    pdftotext = which("pdftotext")
    if pdftotext:
        try:
            with tempfile.TemporaryDirectory() as tmpdir:
                out_path = Path(tmpdir) / "out.txt"
                proc = subprocess.run(
                    [pdftotext, "-layout", "-enc", "UTF-8", "-l", str(max_pages), str(pdf_path), str(out_path)],
                    capture_output=True,
                    text=True,
                    timeout=60,
                )
                if proc.returncode == 0 and out_path.exists():
                    text = out_path.read_text(encoding="utf-8", errors="ignore")
                    if len(text.strip()) >= 50:
                        return text, "pdftotext"
        except Exception:
            pass

    # Fallback to pymupdf
    try:
        import fitz
        doc = fitz.open(str(pdf_path))
        texts = []
        for i, page in enumerate(doc):
            if i >= max_pages:
                break
            texts.append(page.get_text())
        doc.close()
        text = "\n\n".join(texts)
        if text.strip():
            return text, "pymupdf"
    except ImportError:
        pass
    except Exception:
        pass

    return "", "none"


def truncate_text(text: str, max_chars: int = 45000) -> str:
    """Truncate text to max characters, keeping head and tail."""
    if len(text) <= max_chars:
        return text
    head = int(max_chars * 0.7)
    tail = max_chars - head
    return text[:head] + "\n\n[...truncated...]\n\n" + text[-tail:]


def extract_target_drug_from_filename(filename: str) -> str | None:
    """ä»æ–‡ä»¶åå‰ç¼€æå–ç›®æ ‡è¯ç‰©åç§°ã€‚

    æ ¹æ®ä¸“å®¶åé¦ˆï¼ŒPDFæ–‡ä»¶åæ ¼å¼é€šå¸¸ä¸º: "è¯ç‰©å-æ–‡ç« æ ‡é¢˜.pdf"
    æ–‡ä»¶åå‰ç¼€ï¼ˆç¬¬ä¸€ä¸ª"-"ä¹‹å‰çš„éƒ¨åˆ†ï¼‰å³ä¸ºè¯¥æ–‡çŒ®çš„ç›®æ ‡ç›‘æµ‹è¯ç‰©ã€‚

    Args:
        filename: PDFæ–‡ä»¶å

    Returns:
        ç›®æ ‡è¯ç‰©åç§°ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
    """
    if not filename:
        return None

    # å»é™¤æ‰©å±•å
    name = filename.rsplit('.', 1)[0] if '.' in filename else filename

    # æŒ‰ç¬¬ä¸€ä¸ª "-" åˆ†å‰²ï¼Œå–å‰ç¼€ä½œä¸ºç›®æ ‡è¯ç‰©
    if '-' in name:
        target_drug = name.split('-', 1)[0].strip()
        if target_drug:
            return target_drug

    return None


import re


def search_drug_in_text(text: str, target_drug: str, drug_keywords: list[str]) -> dict:
    """åœ¨å…¨æ–‡ä¸­æœç´¢ç›®æ ‡è¯ç‰©ï¼Œè¿”å›æœç´¢ç»“æœå’Œä¸Šä¸‹æ–‡ã€‚

    Args:
        text: æ–‡ç« å…¨æ–‡
        target_drug: ç›®æ ‡è¯ç‰©åç§°ï¼ˆä»æ–‡ä»¶åæå–ï¼‰
        drug_keywords: è¯ç‰©å…³é”®è¯åˆ—è¡¨ï¼ˆåŒ…å«åˆ«åï¼‰

    Returns:
        dict: {
            'found': bool,  # æ˜¯å¦æ‰¾åˆ°
            'count': int,   # å‡ºç°æ¬¡æ•°
            'matched_terms': list[str],  # åŒ¹é…åˆ°çš„å…·ä½“è¯
            'contexts': list[str],  # ä¸Šä¸‹æ–‡ç‰‡æ®µï¼ˆæœ€å¤š5ä¸ªï¼‰
            'search_terms': list[str],  # æœç´¢çš„å…³é”®è¯
        }
    """
    if not text or not target_drug:
        return {
            'found': False, 'count': 0, 'matched_terms': [],
            'contexts': [], 'search_terms': []
        }

    # æ„å»ºæœç´¢è¯åˆ—è¡¨ï¼šç›®æ ‡è¯ç‰© + ç›¸å…³åˆ«å
    search_terms = [target_drug.lower()]

    # ä»è¯ç‰©å…³é”®è¯åˆ—è¡¨ä¸­æ‰¾ç›¸å…³åˆ«å
    target_lower = target_drug.lower()
    for kw in drug_keywords:
        kw_lower = kw.lower()
        # å¦‚æœå…³é”®è¯åŒ…å«ç›®æ ‡è¯ç‰©æˆ–ç›®æ ‡è¯ç‰©åŒ…å«å…³é”®è¯
        if target_lower in kw_lower or kw_lower in target_lower:
            if kw_lower not in search_terms:
                search_terms.append(kw_lower)
        # å¸¸è§è¯ç‰©åˆ«åæ˜ å°„
        drug_aliases = {
            'å¡é©¬è¥¿å¹³': ['carbamazepine', 'tegretol', 'å¾—ç†å¤š'],
            'å¥¥å¡è¥¿å¹³': ['oxcarbazepine', 'trileptal', 'æ›²è±'],
            'ç¼¬æ²™å¦': ['valsartan', 'ä»£æ–‡'],
            'æ¥æ›²å”‘': ['letrozole', 'èŠ™ç‘'],
            'ç¯å­¢ç´ ': ['cyclosporine', 'ciclosporin', 'æ–°å±±åœ°æ˜', 'sandimmun'],
            'å¸ƒæ—ä½èƒº': ['brinzolamide', 'æ´¾ç«‹æ˜'],
            'å¸åº“å¥‡å°¤å•æŠ—': ['secukinumab', 'å¯å–„æŒº', 'cosentyx'],
            'å¦¥å¸ƒéœ‰ç´ ': ['tobramycin', 'æ‰˜ç™¾å£«'],
            'é›·ç å•æŠ—': ['ranibizumab', 'è¯ºé€‚å¾—', 'lucentis'],
            'æ²™åº“å·´æ›²ç¼¬æ²™å¦': ['sacubitril/valsartan', 'è¯ºæ¬£å¦¥', 'entresto'],
            'ç”²ç£ºé…¸ä¼Šé©¬æ›¿å°¼': ['imatinib', 'æ ¼åˆ—å«', 'gleevec', 'glivec'],
            'ä¼Šé©¬æ›¿å°¼': ['imatinib', 'æ ¼åˆ—å«', 'gleevec', 'glivec'],
            'octreotide': ['å¥¥æ›²è‚½', 'å–„é¾™', 'sandostatin'],
            'pazopanib': ['å¸•å”‘å¸•å°¼', 'ç»´å…¨ç‰¹', 'votrient'],
        }
        for main_name, aliases in drug_aliases.items():
            if target_lower == main_name.lower() or target_lower in [a.lower() for a in aliases]:
                for alias in aliases:
                    if alias.lower() not in search_terms:
                        search_terms.append(alias.lower())
                if main_name.lower() not in search_terms:
                    search_terms.append(main_name.lower())

    # åœ¨æ–‡æœ¬ä¸­æœç´¢
    text_lower = text.lower()
    # åˆ›å»ºå»é™¤ç©ºæ ¼çš„ç‰ˆæœ¬ï¼ˆå¤„ç†OCRç©ºæ ¼é—®é¢˜ï¼Œå¦‚"å¡ é©¬ è¥¿ å¹³"ï¼‰
    text_no_space = re.sub(r'\s+', '', text_lower)

    matched_terms = []
    all_positions = []

    for term in search_terms:
        term_lower = term.lower()
        term_no_space = re.sub(r'\s+', '', term_lower)

        # æ–¹æ³•1: ç›´æ¥åŒ¹é…ï¼ˆåŸæ–‡æœ¬ï¼‰
        pattern = re.escape(term_lower)
        matches = list(re.finditer(pattern, text_lower))
        if matches:
            matched_terms.append(term)
            for m in matches:
                all_positions.append((m.start(), m.end(), term))

        # æ–¹æ³•2: å»ç©ºæ ¼ååŒ¹é…ï¼ˆå¤„ç†OCRé—®é¢˜ï¼‰
        if not matches and len(term_no_space) >= 2:
            # åœ¨å»ç©ºæ ¼çš„æ–‡æœ¬ä¸­æœç´¢
            pattern_no_space = re.escape(term_no_space)
            matches_no_space = list(re.finditer(pattern_no_space, text_no_space))
            if matches_no_space:
                matched_terms.append(f"{term}(OCRä¿®æ­£)")
                # ä¼°ç®—åŸæ–‡ä½ç½®ï¼ˆä¸ç²¾ç¡®ä½†è¶³å¤Ÿï¼‰
                for m in matches_no_space:
                    # ä½¿ç”¨å»ç©ºæ ¼ä½ç½®çš„1.5å€ä½œä¸ºä¼°ç®—
                    est_pos = int(m.start() * 1.5)
                    all_positions.append((est_pos, est_pos + len(term), term))

        # æ–¹æ³•3: å…è®¸å­—ç¬¦é—´æœ‰ç©ºæ ¼çš„æ¨¡å¼ï¼ˆå¦‚"å¡ é©¬ è¥¿ å¹³"ï¼‰
        if not matches and len(term_lower) >= 2:
            # æ„å»ºå…è®¸ç©ºæ ¼çš„æ­£åˆ™ï¼šå¡\s*é©¬\s*è¥¿\s*å¹³
            spaced_pattern = r'\s*'.join(re.escape(c) for c in term_lower)
            matches_spaced = list(re.finditer(spaced_pattern, text_lower))
            if matches_spaced:
                if term not in matched_terms and f"{term}(OCRä¿®æ­£)" not in matched_terms:
                    matched_terms.append(f"{term}(ç©ºæ ¼)")
                for m in matches_spaced:
                    all_positions.append((m.start(), m.end(), term))

    # å»é‡å¹¶æ’åºä½ç½®
    all_positions = sorted(set(all_positions), key=lambda x: x[0])

    # æå–ä¸Šä¸‹æ–‡ï¼ˆå‰åå„50ä¸ªå­—ç¬¦ï¼‰
    contexts = []
    used_ranges = []
    for start, end, term in all_positions[:10]:  # æœ€å¤šå¤„ç†10ä¸ªåŒ¹é…
        # é¿å…é‡å çš„ä¸Šä¸‹æ–‡
        overlap = False
        for used_start, used_end in used_ranges:
            if not (end + 50 < used_start or start - 50 > used_end):
                overlap = True
                break
        if overlap:
            continue

        ctx_start = max(0, start - 50)
        ctx_end = min(len(text), end + 50)
        context = text[ctx_start:ctx_end].replace('\n', ' ').strip()
        # æ ‡è®°åŒ¹é…è¯
        context = f"...{context}..."
        contexts.append(context)
        used_ranges.append((ctx_start, ctx_end))

        if len(contexts) >= 5:
            break

    return {
        'found': len(matched_terms) > 0,
        'count': len(all_positions),
        'matched_terms': list(set(matched_terms)),
        'contexts': contexts,
        'search_terms': search_terms[:10],  # åªè¿”å›å‰10ä¸ªæœç´¢è¯
    }


# æ–‡ç« ç±»å‹å¸¸é‡
ARTICLE_TYPES = {
    'animal_study': 'åŠ¨ç‰©å®éªŒ',
    'case_report': 'ç—…ä¾‹æŠ¥å‘Š',
    'review': 'ç»¼è¿°/æŒ‡å—',
    'clinical_study': 'ä¸´åºŠç ”ç©¶',
    'unknown': 'æœªçŸ¥ç±»å‹',
}


def detect_article_type(text: str, filename: str) -> dict:
    """åŸºäºå…³é”®è¯æ£€æµ‹æ–‡ç« ç±»å‹ã€‚

    Args:
        text: æ–‡ç« å…¨æ–‡
        filename: æ–‡ä»¶åï¼ˆç”¨äºæå–æ ‡é¢˜ï¼‰

    Returns:
        dict: {
            'type': str,  # æ–‡ç« ç±»å‹ä»£ç 
            'type_cn': str,  # æ–‡ç« ç±»å‹ä¸­æ–‡
            'confidence': float,  # ç½®ä¿¡åº¦
            'evidence': list[str],  # åŒ¹é…åˆ°çš„å…³é”®è¯è¯æ®
        }
    """
    if not text:
        return {'type': 'unknown', 'type_cn': 'æœªçŸ¥ç±»å‹', 'confidence': 0.0, 'evidence': []}

    text_lower = text.lower()
    # æå–æ ‡é¢˜ï¼ˆæ–‡ä»¶åä¸­"-"åé¢çš„éƒ¨åˆ†ï¼Œæˆ–å‰2000å­—ç¬¦ï¼‰
    title = filename.split('-', 1)[1] if '-' in filename else filename
    title = title.rsplit('.', 1)[0] if '.' in title else title
    title_lower = title.lower()

    # æ–‡ç« å¼€å¤´éƒ¨åˆ†ï¼ˆæ›´é‡è¦ï¼‰
    text_head = text_lower[:3000]

    evidence = []
    scores = {
        'animal_study': 0,
        'case_report': 0,
        'review': 0,
        'clinical_study': 0,
    }

    # ========== åŠ¨ç‰©å®éªŒæ£€æµ‹ ==========
    animal_keywords = {
        'å°é¼ ': 3, 'å¤§é¼ ': 3, 'mice': 3, 'mouse': 3, 'rat': 3, 'rats': 3,
        'å®éªŒåŠ¨ç‰©': 3, 'åŠ¨ç‰©å®éªŒ': 3, 'åŠ¨ç‰©æ¨¡å‹': 3, 'animal model': 3,
        'é€ æ¨¡': 2, 'æ¨¡å‹ç»„': 2, 'å®éªŒç»„å¤§é¼ ': 3, 'å®éªŒç»„å°é¼ ': 3,
        'çŒèƒƒ': 2, 'è…¹è…”æ³¨å°„': 2, 'å°¾é™è„‰': 2,
        'å…”': 1, 'è±šé¼ ': 2, 'çŠ¬': 1,
    }
    for kw, score in animal_keywords.items():
        # æ£€æŸ¥å»ç©ºæ ¼ç‰ˆæœ¬ï¼ˆå¤„ç†OCRé—®é¢˜ï¼‰
        kw_no_space = kw.replace(' ', '')
        text_no_space = re.sub(r'\s+', '', text_lower)
        if kw in text_lower or kw_no_space in text_no_space:
            scores['animal_study'] += score
            evidence.append(f"åŠ¨ç‰©å®éªŒ:{kw}")

    # å¦‚æœæœ‰"æ‚£è€…"å‡ºç°åœ¨å‰2000å­—ç¬¦ï¼Œé™ä½åŠ¨ç‰©å®éªŒå¾—åˆ†
    if 'æ‚£è€…' in text_head or 'patient' in text_head:
        scores['animal_study'] = max(0, scores['animal_study'] - 3)

    # ========== ç—…ä¾‹æŠ¥å‘Šæ£€æµ‹ ==========
    case_keywords = {
        '1ä¾‹': 4, 'ä¸€ä¾‹': 4, '1 ä¾‹': 4,
        'ä¸ªæ¡ˆ': 3, 'ç—…ä¾‹æŠ¥å‘Š': 4, 'case report': 4,
        'æ¡ˆä¾‹åˆ†äº«': 4, 'ç—…æ¡ˆåˆ†äº«': 4, 'ç—…æ¡ˆ': 2,
        'ä¸ªä¾‹': 3, 'å•ä¾‹': 3,
    }
    for kw, score in case_keywords.items():
        if kw in title_lower:
            scores['case_report'] += score + 2  # æ ‡é¢˜ä¸­å‡ºç°æƒé‡æ›´é«˜
            evidence.append(f"ç—…ä¾‹æŠ¥å‘Š(æ ‡é¢˜):{kw}")
        elif kw in text_head:
            scores['case_report'] += score
            evidence.append(f"ç—…ä¾‹æŠ¥å‘Š:{kw}")

    # ========== ç»¼è¿°/æŒ‡å—æ£€æµ‹ ==========
    review_keywords = {
        'ç»¼è¿°': 4, 'è¿›å±•': 3, 'ç ”ç©¶è¿›å±•': 4,
        'æŒ‡å—': 4, 'guideline': 4, 'review': 3,
        'ä¸“å®¶å…±è¯†': 4, 'è¯Šç–—è§„èŒƒ': 3, 'è¯Šæ²»è¿›å±•': 3,
        'æ–‡çŒ®å¤ä¹ ': 3, 'ç³»ç»Ÿè¯„ä»·': 3, 'metaåˆ†æ': 3, 'meta-analysis': 3,
    }
    for kw, score in review_keywords.items():
        if kw in title_lower:
            scores['review'] += score + 2
            evidence.append(f"ç»¼è¿°(æ ‡é¢˜):{kw}")
        elif kw in text_head:
            scores['review'] += score
            evidence.append(f"ç»¼è¿°:{kw}")

    # ========== ä¸´åºŠç ”ç©¶æ£€æµ‹ ==========
    clinical_keywords = {
        'ä¸´åºŠç ”ç©¶': 4, 'ä¸´åºŠè¯•éªŒ': 4, 'clinical trial': 4, 'clinical study': 4,
        'éšæœº': 3, 'å¯¹ç…§ç»„': 3, 'è§‚å¯Ÿç»„': 3, 'æ²»ç–—ç»„': 3,
        'çº³å…¥æ ‡å‡†': 3, 'æ’é™¤æ ‡å‡†': 3, 'å…¥ç»„': 2,
        'ä¾‹æ‚£è€…': 3, 'åæ‚£è€…': 3,
        'å›é¡¾æ€§åˆ†æ': 3, 'å‰ç»æ€§': 3,
        'n=': 2, 'p<': 2, 'p=': 2, 'på€¼': 2,
    }
    for kw, score in clinical_keywords.items():
        if kw in text_lower:
            scores['clinical_study'] += score
            evidence.append(f"ä¸´åºŠç ”ç©¶:{kw}")

    # ========== ç¡®å®šæœ€ç»ˆç±»å‹ ==========
    max_score = max(scores.values())
    if max_score < 3:
        return {
            'type': 'unknown',
            'type_cn': 'æœªçŸ¥ç±»å‹',
            'confidence': 0.5,
            'evidence': evidence[:5],
        }

    # æ‰¾å‡ºå¾—åˆ†æœ€é«˜çš„ç±»å‹
    best_type = max(scores, key=scores.get)

    # è®¡ç®—ç½®ä¿¡åº¦
    total_score = sum(scores.values()) or 1
    confidence = min(0.95, 0.5 + (scores[best_type] / total_score) * 0.5)

    return {
        'type': best_type,
        'type_cn': ARTICLE_TYPES[best_type],
        'confidence': round(confidence, 2),
        'evidence': evidence[:5],
    }


def classify_by_rules(
    has_drug: bool,
    has_ae: bool,
    has_causality: bool,
    has_special_situation: bool,
    patient_mode: str,
) -> str:
    """Rule-based classification logic.

    åˆ†ç±»åˆ¤æ–­é€»è¾‘ï¼ˆæ ¹æ®ä¸“å®¶åé¦ˆä¿®è®¢ v2ï¼‰ï¼š
    1. Rejectionï¼šç¼ºå°‘drugï¼Œæˆ–è€…æ—¢æ— AEä¹Ÿæ— ç‰¹æ®Šæƒ…å†µï¼ˆå®Œå…¨æ— å®‰å…¨ç›‘æµ‹ä»·å€¼ï¼‰
    2. ICSRï¼šdrug + (AE+å› æœå…³ç³» OR ç‰¹æ®Šæƒ…å†µ) + å•ä¸ªæ‚£è€…
    3. Multiple_Patientsï¼šdrug + (AE+å› æœå…³ç³» OR ç‰¹æ®Šæƒ…å†µ) + å¤šä¸ªæ‚£è€…
    4. ICSR+Multiple_Patientsï¼šä¸€ç¯‡æ–‡ç« åŒæ—¶æ»¡è¶³ICSRå’ŒMultiple_Patientsçš„æ¡ä»¶
    5. Other_Safety_Signalï¼šæœ‰drugä¸”æœ‰AE/ç‰¹æ®Šæƒ…å†µï¼Œä½†ç¼ºå°‘å› æœå…³ç³»æˆ–æ‚£è€…ä¿¡æ¯ï¼ˆæœ‰é£é™©ï¼Œéœ€å…³æ³¨ï¼‰

    å…³é”®ä¿®è®¢ï¼š
    - ç‰¹æ®Šæƒ…å†µï¼ˆå„¿ç«¥ç”¨è¯ã€è¯ç‰©æ— æ•ˆç­‰ï¼‰å¯ä»¥ç‹¬ç«‹æ„æˆå®‰å…¨ä¿¡å·ï¼Œä¸éœ€è¦AE
    - åªæœ‰å®Œå…¨æ— å®‰å…¨ä»·å€¼æ‰Rejectionï¼Œæœ‰drug+AE/ç‰¹æ®Šæƒ…å†µè‡³å°‘æ˜¯Signal
    """
    # Rejection: ç¼ºå°‘è¯ç‰©
    if not has_drug:
        return "Rejection"

    # åˆ¤æ–­æ˜¯å¦æœ‰å®‰å…¨ä¿¡å·ä»·å€¼ï¼šæœ‰AEæˆ–æœ‰ç‰¹æ®Šæƒ…å†µ
    has_safety_signal = has_ae or has_special_situation

    # Rejection: æ—¢æ— AEä¹Ÿæ— ç‰¹æ®Šæƒ…å†µï¼ˆå®Œå…¨æ— å®‰å…¨ç›‘æµ‹ä»·å€¼ï¼‰
    if not has_safety_signal:
        return "Rejection"

    # æ»¡è¶³ICSR/Multiple_Patientsçš„æ¡ä»¶ï¼š
    # - (AE + å› æœå…³ç³») OR ç‰¹æ®Šæƒ…å†µ
    # ç‰¹æ®Šæƒ…å†µï¼ˆå„¿ç«¥ç”¨è¯ã€è¯ç‰©æ— æ•ˆã€å¦Šå¨ æš´éœ²ç­‰ï¼‰å¯ä»¥ç‹¬ç«‹æ„æˆå®‰å…¨ä¿¡å·
    meets_criteria = (has_ae and has_causality) or has_special_situation

    if patient_mode == "single":
        # å•ä¸ªæ‚£è€…ï¼šæ»¡è¶³æ¡ä»¶åˆ™ICSRï¼Œå¦åˆ™Other_Safety_Signal
        return "ICSR" if meets_criteria else "Other_Safety_Signal"

    if patient_mode == "multiple":
        # å¤šä¸ªæ‚£è€…(>1ä¾‹)ï¼šæ»¡è¶³æ¡ä»¶åˆ™Multiple_Patientsï¼Œå¦åˆ™Other_Safety_Signal
        return "Multiple_Patients" if meets_criteria else "Other_Safety_Signal"

    if patient_mode == "mixed":
        # æ··åˆ(åŒæ—¶æœ‰å•æ‚£è€…å’Œå¤šæ‚£è€…æè¿°)ï¼šæ»¡è¶³æ¡ä»¶åˆ™ICSR+Multiple_Patients
        return "ICSR+Multiple_Patients" if meets_criteria else "Other_Safety_Signal"

    # å…¶ä»–æƒ…å†µï¼ˆunknownç­‰ï¼‰ï¼šæœ‰drug+AE/ç‰¹æ®Šæƒ…å†µä½†ç¼ºå°‘æ‚£è€…ä¿¡æ¯ï¼Œä»æœ‰é£é™©ä»·å€¼
    return "Other_Safety_Signal"


def classify_with_openai(text: str, filename: str, drug_keywords: list[str]) -> ClassificationResult:
    """Classify paper using OpenAI GPT for drug safety."""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return ClassificationResult(
            filename=filename, label="Error", label_cn="é”™è¯¯",
            has_drug=False, has_ae=False, has_causality=False, has_special_situation=False,
            patient_mode="unknown", patient_max_n=None, confidence=0.0,
            drug_evidence=[], ae_evidence=[], causality_evidence=[],
            special_evidence=[], patient_evidence=[],
            has_drug_reasoning="", has_ae_reasoning="", has_causality_reasoning="",
            has_special_reasoning="", patient_reasoning="", reasoning="",
            needs_review=True, extract_method="", text_length=0,
            error="OPENAI_API_KEY not set"
        )

    client = OpenAI(api_key=api_key)
    drug_hint = ", ".join(drug_keywords[:100]) if drug_keywords else "(æœªæä¾›è¯ç‰©å…³é”®è¯)"

    # ä»æ–‡ä»¶åæå–ç›®æ ‡è¯ç‰©
    target_drug = extract_target_drug_from_filename(filename)
    target_drug_hint = f"ã€{target_drug}ã€‘" if target_drug else "(æ— æ³•ä»æ–‡ä»¶åæå–)"

    # æ–‡ç« ç±»å‹æ£€æµ‹
    article_type_result = detect_article_type(text, filename)

    # å…¨æ–‡æœç´¢ç›®æ ‡è¯ç‰©
    drug_search_result = search_drug_in_text(text, target_drug, drug_keywords) if target_drug else None

    system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è¯ç‰©è­¦æˆ’ä¿¡æ¯æå–ä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä»åŒ»å­¦/ç§‘å­¦æ–‡çŒ®ä¸­æå–å…³é”®å®‰å…¨ä¿¡æ¯ï¼Œç”¨äºè¯ºåè¯ç‰©å®‰å…¨ç›‘æµ‹ã€‚

æ–‡çŒ®æ£€ç´¢ä¸šåŠ¡èƒŒæ™¯ï¼š
åœ¨å…¨æ–‡èŒƒå›´å†…ä»¥ä¸­è‹±æ–‡å•†å“å&æ´»æ€§æˆåˆ†åä½œä¸ºå…³é”®è¯è¿›è¡Œæ£€ç´¢ï¼Œæ£€ç´¢å‡ºä¸ŠæŠ›åˆ°CNKI & Wanfangæ•°æ®åº“ä¸­çš„æ–‡çŒ®ã€‚
é’ˆå¯¹æ‰€æœ‰æ£€ç´¢å‡ºæ¥çš„æ–‡çŒ®è¿›è¡Œå®¡é˜…ï¼Œè¯†åˆ«æ–‡ç« ä¸­æ˜¯å¦æåŠä»»ä½•è¯ºåè¯ç›¸å…³å®‰å…¨ç—…ä¾‹æˆ–æ½œåœ¨ä¿¡å·ã€‚

âš ï¸ é‡è¦ï¼šç›®æ ‡è¯ç‰©åˆ¤æ–­è§„åˆ™ï¼ˆæ ¹æ®ä¸“å®¶åé¦ˆä¿®è®¢ï¼‰
- PDFæ–‡ä»¶åæ ¼å¼ä¸º: "ç›®æ ‡è¯ç‰©å-æ–‡ç« æ ‡é¢˜.pdf"
- **æ–‡ä»¶åå‰ç¼€ï¼ˆç¬¬ä¸€ä¸ª"-"ä¹‹å‰çš„éƒ¨åˆ†ï¼‰å³ä¸ºè¯¥æ–‡çŒ®çš„ç›®æ ‡ç›‘æµ‹è¯ç‰©**
- å³ä½¿æ–‡ç« å†…å®¹ä¸»è¦è®¨è®ºçš„æ˜¯å…¶ä»–è¯ç‰©ï¼Œåªè¦æ–‡ä¸­æåŠäº†æ–‡ä»¶åå‰ç¼€æ‰€ç¤ºçš„ç›®æ ‡è¯ç‰©ï¼Œå°±åº”è¯¥åˆ¤å®šhas_drug=True
- ä¾‹å¦‚: "å¡é©¬è¥¿å¹³-å·¦ä¹™æ‹‰è¥¿å¦è‡´å‰¥è„±æ€§çš®ç‚.pdf" â†’ ç›®æ ‡è¯ç‰©æ˜¯"å¡é©¬è¥¿å¹³"ï¼Œä¸æ˜¯"å·¦ä¹™æ‹‰è¥¿å¦"

åˆ†ç±»åˆ¤æ–­é€»è¾‘ï¼ˆæ ¹æ®ä¸“å®¶åé¦ˆä¿®è®¢ v2ï¼‰ï¼š
1. Rejectionï¼šç¼ºå°‘drugï¼Œæˆ–è€…æ—¢æ— AEä¹Ÿæ— ç‰¹æ®Šæƒ…å†µï¼ˆå®Œå…¨æ— å®‰å…¨ç›‘æµ‹ä»·å€¼ï¼‰
2. ICSRï¼šdrug + (AE+å› æœå…³ç³» OR ç‰¹æ®Šæƒ…å†µ) + å•ä¸ªæ‚£è€…
3. Multiple_Patientsï¼šdrug + (AE+å› æœå…³ç³» OR ç‰¹æ®Šæƒ…å†µ) + å¤šä¸ªæ‚£è€…
4. ICSR+Multiple_Patientsï¼šä¸€ç¯‡æ–‡ç« åŒæ—¶æ»¡è¶³ICSRå’ŒMultiple_Patientsçš„æ¡ä»¶
5. Other_Safety_Signalï¼šæœ‰drugä¸”æœ‰AE/ç‰¹æ®Šæƒ…å†µï¼Œä½†ç¼ºå°‘å› æœå…³ç³»æˆ–æ‚£è€…ä¿¡æ¯ï¼ˆæœ‰é£é™©ï¼Œéœ€å…³æ³¨ï¼‰

å…³é”®ä¿®è®¢ï¼š
- ç‰¹æ®Šæƒ…å†µï¼ˆå„¿ç«¥ç”¨è¯ã€è¯ç‰©æ— æ•ˆç­‰ï¼‰å¯ä»¥ç‹¬ç«‹æ„æˆå®‰å…¨ä¿¡å·ï¼Œä¸éœ€è¦AE
- åªæœ‰å®Œå…¨æ— å®‰å…¨ä»·å€¼æ‰Rejectionï¼Œæœ‰drug+AE/ç‰¹æ®Šæƒ…å†µè‡³å°‘æ˜¯Signal

éœ€è¦æå–çš„å­—æ®µï¼š

1. **has_drug** (boolean): æ–‡ç« æ˜¯å¦æåŠç›®æ ‡è¯ç‰©ï¼Ÿ
   - âš ï¸ ç›®æ ‡è¯ç‰© = æ–‡ä»¶åå‰ç¼€ï¼ˆç¬¬ä¸€ä¸ª"-"ä¹‹å‰çš„éƒ¨åˆ†ï¼‰
   - åœ¨æ–‡ç« ä¸­æœç´¢è¯¥ç›®æ ‡è¯ç‰©çš„ä»»ä½•æåŠï¼ˆä¸­è‹±æ–‡åã€å•†å“åã€é€šç”¨åå‡å¯ï¼‰
   - å³ä½¿åªæ˜¯ç®€å•æåŠæˆ–ä½œä¸ºèƒŒæ™¯ä¿¡æ¯ï¼Œä¹Ÿç®—has_drug=True

2. **has_ae** (boolean): æ˜¯å¦æè¿°äº†ä¸è¯ç‰©ä½¿ç”¨ç›¸å…³çš„ä¸è‰¯äº‹ä»¶(AE)ï¼Ÿ
   - âœ… YESçš„æƒ…å†µï¼ˆå¿…é¡»æ˜¯äººä½“ä¸´åºŠä¸­å®é™…å‘ç”Ÿçš„ï¼‰ï¼š
     - ç—…ä¾‹æŠ¥å‘Šä¸­å…·ä½“æ‚£è€…ç”¨è¯åå‡ºç°çš„ä¸è‰¯ååº”
     - ä¸´åºŠç ”ç©¶ä¸­æ˜ç¡®è®°å½•çš„ä¸è‰¯ååº”æ•°æ®å’Œå‘ç”Ÿç‡
     - æœ‰å…·ä½“æ‚£è€…ã€å…·ä½“ç—‡çŠ¶ã€å…·ä½“æ—¶é—´çš„AEæè¿°
   - âŒ NOçš„æƒ…å†µï¼ˆå¿…é¡»ä¸¥æ ¼æ’é™¤ï¼‰ï¼š
     - ç»¼è¿°/æŒ‡å—ä¸­å‡è®¾æ€§è®¨è®ºï¼ˆå¦‚"è¯¥è¯å¯èƒ½å¯¼è‡´XX"ã€"å¸¸è§å‰¯ä½œç”¨åŒ…æ‹¬"ï¼‰
     - ä»…åˆ—ä¸¾è¯ç‰©åç§°å’Œç–¾ç—…åç§°ï¼Œä½†æ— å…·ä½“ç—…ä¾‹è¯æ®
     - åŠ¨ç‰©å®éªŒä¸­çš„æ¯’æ€§ååº”ï¼ˆä¸ç®—äººä½“AEï¼‰
     - ç–¾ç—…æœ¬èº«ç—‡çŠ¶ï¼ˆå¦‚è‚¿ç˜¤æ‚£è€…çš„è…¹æ³»æ˜¯ç–¾ç—…ç—‡çŠ¶ï¼Œéè¯ç‰©AEï¼‰
     - æ–‡çŒ®èƒŒæ™¯ä»‹ç»ä¸­æåŠçš„ä¸€èˆ¬æ€§é£é™©è®¨è®º
   - âš ï¸ å…³é”®åˆ¤æ–­ï¼šå¿…é¡»æ˜¯"äººä½“ä¸´åºŠä¸­å®é™…å‘ç”Ÿçš„ã€æœ‰å…·ä½“è¯æ®çš„è¯ç‰©ç›¸å…³AE"

3. **has_causality** (boolean): æ˜¯å¦æœ‰å› æœå…³ç³»è¡¨è¿°å°†è¯ç‰©ä¸ä¸è‰¯äº‹ä»¶è”ç³»èµ·æ¥ï¼Ÿ
   - âœ… YESçš„æƒ…å†µï¼š
     - æ˜ç¡®å½’å› ï¼š"ä¸...ç›¸å…³"ã€"ç”±...å¼•èµ·"ã€"å½’å› äº"ã€"è¯ç‰©è¯±å‘"ã€"å¯¼è‡´"
     - æ—¶é—´å…³è”+æ˜ç¡®å› æœï¼š"ç”¨è¯åå‡ºç°XXç—‡çŠ¶"ã€"æ²»ç–—æœŸé—´å‘ç”Ÿ"ã€"åœè¯åç¼“è§£"
     - å»æ¿€å‘/å†æ¿€å‘é˜³æ€§
     - ç—…ä¾‹æŠ¥å‘Šä¸­æ˜ç¡®æè¿°è¯ç‰©å¼•èµ·çš„ç—‡çŠ¶
     - âš ï¸ ä¸´åºŠç ”ç©¶éšå«å› æœï¼ˆæ–°å¢ï¼‰ï¼š
       * "æ²»ç–—æœŸé—´è®°å½•ä¸è‰¯ååº”"ã€"è§‚å¯ŸæŒ‡æ ‡åŒ…æ‹¬ä¸è‰¯ååº”"
       * "ä¸¤ç»„ä¸è‰¯ååº”æ¯”è¾ƒ"ã€"è¯•éªŒç»„vså¯¹ç…§ç»„AEå‘ç”Ÿç‡"
       * å¯¹ç…§ç ”ç©¶è®¾è®¡æœ¬èº«éšå«äº†å¯¹æ²»ç–—ç›¸å…³AEçš„å› æœåˆ¤æ–­
   - âŒ NOçš„æƒ…å†µï¼š
     - ç»¼è¿°/æŒ‡å—ä»…æ³›æ³›è®¨è®ºè¯ç‰©å¯èƒ½çš„å‰¯ä½œç”¨ï¼ˆæ— å…·ä½“ç—…ä¾‹ï¼‰
     - æ˜ç¡®å¦å®šå› æœå…³ç³»
     - ä»…æè¿°ç–¾ç—…è‡ªç„¶ç—…ç¨‹
   - âš ï¸ ä¸´åºŠç ”ç©¶ä¸­å¦‚æœå°†"ä¸è‰¯ååº”"ä½œä¸ºè§‚å¯ŸæŒ‡æ ‡ï¼Œå³è§†ä¸ºå­˜åœ¨éšå«å› æœ

4. **has_special_situation** (boolean): æ˜¯å¦å­˜åœ¨ä»¥ä¸‹ç‰¹æ®Šæƒ…å†µï¼Ÿâš ï¸ ç‰¹æ®Šæƒ…å†µå¯ç‹¬ç«‹æ„æˆå®‰å…¨ä¿¡å·
   - å¦Šå¨ /å“ºä¹³æœŸæš´éœ² (Pregnancy/lactation exposure)
   - å„¿ç«¥ç”¨è¯ (Pediatric use - æ‚£è€…ä¸ºå„¿ç«¥/å©´å¹¼å„¿)
   - è¯ç‰©æ— æ•ˆ/ç–—æ•ˆä¸ä½³ï¼ˆéœ€æ˜ç¡®è¡¨è¿°ï¼‰ï¼š"æ— æ•ˆ"ã€"æ²»ç–—å¤±è´¥"ã€"æœªèƒ½æ§åˆ¶"
   - è¿‡é‡ (Overdose)
   - ç”¨è¯é”™è¯¯ (Medication error)
   - è¯ç‰©ç›¸äº’ä½œç”¨ (Drug-drug interaction)
   - è¶…è¯´æ˜ä¹¦ç”¨è¯ (Off-label use)
   - âŒ æ³¨æ„ï¼šå¸¸è§„ä¸´åºŠç ”ç©¶ä¸­çš„"è”åˆç”¨è¯"ã€"åŠ é‡"ä¸ç®—ç‰¹æ®Šæƒ…å†µ

5. **patient_mode** (string): æ‚£è€…è¯†åˆ«
   - "single": å•ä¸ªå¯è¯†åˆ«æ‚£è€…
     * æ ‡é¢˜å«"1ä¾‹"ã€"ä¸ªæ¡ˆ"ã€"ç—…ä¾‹æŠ¥å‘Š"
     * âš ï¸ "æ¡ˆä¾‹åˆ†äº«"/"ç—…ä¾‹åˆ†äº«"ç±»æ–‡çŒ®ï¼šå³ä½¿åŒ…å«å¤šä¸ªç—…ä¾‹ï¼ˆç—…æ¡ˆ1ã€ç—…æ¡ˆ2ï¼‰ï¼Œæ¯ä¸ªç—…ä¾‹ä»æ˜¯ç‹¬ç«‹çš„å•æ‚£è€…æŠ¥å‘Šï¼Œåº”åˆ¤ä¸ºsingle
   - "multiple": å¤šä¸ªæ‚£è€…ï¼ˆé˜Ÿåˆ—ç ”ç©¶ã€ä¸´åºŠè¯•éªŒã€å›é¡¾æ€§åˆ†æï¼‰
     * å¿…é¡»æœ‰æ˜ç¡®æ ·æœ¬é‡ï¼ˆå¦‚"çº³å…¥100ä¾‹"ã€"n=50"ï¼‰
     * å¿…é¡»æ˜¯å¤šä¾‹æ‚£è€…çš„åˆå¹¶ç ”ç©¶/ç»Ÿè®¡åˆ†æ
   - "mixed": æ–‡ç« ä¸­æ—¢æœ‰å•æ‚£è€…ç—…ä¾‹ï¼Œåˆæœ‰å¤šæ‚£è€…ç»Ÿè®¡æ•°æ®
   - "unknown": ç»¼è¿°/æŒ‡å—ï¼Œæ— æ˜ç¡®æ‚£è€…ä¿¡æ¯
   - âš ï¸ ä¼˜å…ˆçº§è§„åˆ™ï¼šå…ˆè¯†åˆ«æ–‡çŒ®ç±»å‹ï¼Œå†åˆ¤æ–­æ‚£è€…æ¨¡å¼ã€‚"æ¡ˆä¾‹åˆ†äº«"ä¼˜å…ˆåˆ¤ä¸ºsingle

ä»…è¿”å›åŒ…å«è¿™äº›å­—æ®µå’Œè¯æ®æ•°ç»„çš„JSONå¯¹è±¡ã€‚"""

    # æ„å»ºè¯ç‰©æœç´¢ç»“æœæç¤º
    if drug_search_result and drug_search_result['found']:
        drug_search_info = f"""
ğŸ“ ã€å…¨æ–‡æ£€ç´¢ç»“æœã€‘ç›®æ ‡è¯ç‰©åœ¨æ–‡ä¸­å‡ºç°æƒ…å†µï¼š
   - æ£€ç´¢çŠ¶æ€: âœ… æ‰¾åˆ°
   - å‡ºç°æ¬¡æ•°: {drug_search_result['count']}æ¬¡
   - åŒ¹é…è¯: {', '.join(drug_search_result['matched_terms'])}
   - ä¸Šä¸‹æ–‡ç‰‡æ®µ:
"""
        for i, ctx in enumerate(drug_search_result['contexts'][:3], 1):
            drug_search_info += f"     [{i}] {ctx}\n"
    elif drug_search_result:
        drug_search_info = f"""
ğŸ“ ã€å…¨æ–‡æ£€ç´¢ç»“æœã€‘ç›®æ ‡è¯ç‰©åœ¨æ–‡ä¸­å‡ºç°æƒ…å†µï¼š
   - æ£€ç´¢çŠ¶æ€: âŒ æœªæ‰¾åˆ°
   - æœç´¢è¯: {', '.join(drug_search_result['search_terms'][:5])}
   - âš ï¸ æ³¨æ„ï¼šå…¨æ–‡æ£€ç´¢æœªæ‰¾åˆ°ç›®æ ‡è¯ç‰©ï¼Œè¯·ä»”ç»†æ ¸å®æ–‡ç« å†…å®¹
"""
    else:
        drug_search_info = ""

    # æ„å»ºæ–‡ç« ç±»å‹æç¤º
    article_type_info = f"""
ğŸ“‹ ã€æ–‡ç« ç±»å‹æ£€æµ‹ã€‘
   - æ£€æµ‹ç»“æœ: {article_type_result['type_cn']}
   - ç½®ä¿¡åº¦: {article_type_result['confidence']}
   - è¯æ®: {', '.join(article_type_result['evidence'][:3]) if article_type_result['evidence'] else 'æ— '}
"""

    # æ ¹æ®æ–‡ç« ç±»å‹ç”Ÿæˆç‰¹å®šçš„åˆ¤æ–­æŒ‡å¯¼ï¼ˆæŸ”å’Œå»ºè®®ï¼Œä¸å¼ºåˆ¶ï¼‰
    if article_type_result['type'] == 'animal_study':
        type_specific_guidance = """
ğŸ’¡ ã€ä»…ä¾›å‚è€ƒã€‘è§„åˆ™æ£€æµ‹æç¤ºæœ¬æ–‡å¯èƒ½æ˜¯"åŠ¨ç‰©å®éªŒ"ç±»å‹ï¼Œä½†è¯·ä»¥å®é™…å†…å®¹ä¸ºå‡†ï¼š
   - çº¯åŠ¨ç‰©å®éªŒï¼ˆè¯ç‰©ä»…ç”¨äºé€ æ¨¡ï¼‰é€šå¸¸ä¸å«äººä½“å®‰å…¨ä¿¡æ¯
   - ä½†å¦‚æœæ–‡ç« åŒæ—¶è®¨è®ºäº†äººä½“å®‰å…¨æ€§æ•°æ®ã€å·²çŸ¥AEç­‰ï¼Œä»å¯èƒ½æœ‰ä»·å€¼
   - è¯·æ ¹æ®æ–‡ç« å®é™…å†…å®¹è‡ªä¸»åˆ¤æ–­"""
    elif article_type_result['type'] == 'review':
        type_specific_guidance = """
ğŸ’¡ ã€ä»…ä¾›å‚è€ƒã€‘è§„åˆ™æ£€æµ‹æç¤ºæœ¬æ–‡å¯èƒ½æ˜¯"ç»¼è¿°/æŒ‡å—"ç±»å‹ï¼Œä½†è¯·ä»¥å®é™…å†…å®¹ä¸ºå‡†ï¼š
   - ç»¼è¿°ä¸­å¦‚æœä»…æ³›æ³›è®¨è®ºå¯èƒ½çš„å‰¯ä½œç”¨ï¼Œä¸€èˆ¬ä¸ç®—å…·ä½“AE
   - ä½†å¦‚æœç»¼è¿°ä¸­å¼•ç”¨äº†å…·ä½“ç—…ä¾‹æˆ–AEæ•°æ®ç»Ÿè®¡ï¼Œå¯æŒ‰å®é™…æƒ…å†µåˆ¤æ–­
   - è¯·æ ¹æ®æ–‡ç« å®é™…å†…å®¹è‡ªä¸»åˆ¤æ–­"""
    elif article_type_result['type'] == 'case_report':
        type_specific_guidance = """
ğŸ’¡ ã€ä»…ä¾›å‚è€ƒã€‘è§„åˆ™æ£€æµ‹æç¤ºæœ¬æ–‡å¯èƒ½æ˜¯"ç—…ä¾‹æŠ¥å‘Š/æ¡ˆä¾‹åˆ†äº«"ç±»å‹ï¼Œä½†è¯·ä»¥å®é™…å†…å®¹ä¸ºå‡†ï¼š
   - ç—…ä¾‹æŠ¥å‘Šä¸­"ç”¨è¯åå‡ºç°XX"ä¸€èˆ¬å¯è§†ä¸ºå­˜åœ¨å› æœå…³ç³»
   - patient_mode: æ¡ˆä¾‹åˆ†äº«ç±»æ–‡ç« å¯è€ƒè™‘åˆ¤å®šä¸º single
   - è¯·æ ¹æ®æ–‡ç« å®é™…å†…å®¹è‡ªä¸»åˆ¤æ–­"""
    elif article_type_result['type'] == 'clinical_study':
        type_specific_guidance = """
ğŸ’¡ ã€ä»…ä¾›å‚è€ƒã€‘è§„åˆ™æ£€æµ‹æç¤ºæœ¬æ–‡å¯èƒ½æ˜¯"ä¸´åºŠç ”ç©¶"ç±»å‹ï¼Œä½†è¯·ä»¥å®é™…å†…å®¹ä¸ºå‡†ï¼š
   - ä¸´åºŠç ”ç©¶ä¸­è®°å½•çš„ä¸è‰¯ååº”ä¸€èˆ¬å¯è§†ä¸ºå­˜åœ¨å› æœå…³ç³»
   - è¯·æ ¹æ®æ–‡ç« å®é™…å†…å®¹è‡ªä¸»åˆ¤æ–­"""
    else:
        type_specific_guidance = ""

    user_prompt = f"""âš ï¸ æœ¬æ–‡çŒ®çš„ç›®æ ‡ç›‘æµ‹è¯ç‰©ï¼ˆä»æ–‡ä»¶åå‰ç¼€æå–ï¼‰: {target_drug_hint}
æ–‡ä»¶å: {filename}
{article_type_info}{type_specific_guidance}
{drug_search_info}
å…¶ä»–è¯ç‰©å…³é”®è¯å‚è€ƒ: {drug_hint}

æå–æ­¥éª¤:
1. é˜…è¯»æ–‡ç« ï¼Œç†è§£å®é™…å†…å®¹ï¼ˆæ–‡ç« ç±»å‹æ£€æµ‹ä»…ä¾›å‚è€ƒï¼Œä»¥å®é™…å†…å®¹ä¸ºå‡†ï¼‰
2. æ ¹æ®ã€å…¨æ–‡æ£€ç´¢ç»“æœã€‘å’Œæ–‡ç« å†…å®¹ï¼Œåˆ¤æ–­æ˜¯å¦æåˆ°ç›®æ ‡è¯ç‰©
   - å¦‚æœæ£€ç´¢æ‰¾åˆ°ä¸”æœ‰æ˜ç¡®ä¸Šä¸‹æ–‡ï¼Œé€šå¸¸ has_drug=True
   - å¦‚æœè¯ç‰©ä»…ä½œä¸ºå·¥å…·/èƒŒæ™¯æåŠï¼Œæ— å®‰å…¨ç›‘æµ‹ä»·å€¼ï¼Œå¯è€ƒè™‘ has_drug=False
3. åˆ¤æ–­ has_aeï¼š
   - å…³é”®é—®é¢˜ï¼šæ–‡ç« ä¸­æ˜¯å¦æè¿°äº†ä¸è¯ç‰©ç›¸å…³çš„å…·ä½“ä¸è‰¯äº‹ä»¶ï¼Ÿ
   - å…·ä½“çš„æ‚£è€…AEæè¿°ã€AEå‘ç”Ÿç‡ç»Ÿè®¡ â†’ has_ae=True
   - ä»…è®¨è®ºç–¾ç—…æœ¬èº«ç—‡çŠ¶ã€ç†è®ºé£é™© â†’ has_ae=False
4. åˆ¤æ–­ has_causalityï¼š
   - æ˜ç¡®å› æœè¡¨è¿°ï¼ˆ"å¯¼è‡´"ã€"å¼•èµ·"ã€"ç›¸å…³"ï¼‰â†’ has_causality=True
   - ä¸´åºŠç ”ç©¶/ç—…ä¾‹æŠ¥å‘Šä¸­çš„AEä¸€èˆ¬å¯è§†ä¸ºå­˜åœ¨éšå«å› æœå…³ç³»
5. æ£€æŸ¥ç‰¹æ®Šæƒ…å†µï¼ˆå„¿ç«¥ç”¨è¯ã€è¯ç‰©æ— æ•ˆ/ç–—æ•ˆä¸ä½³ã€æ€€å­•æš´éœ²ç­‰ï¼‰
6. åˆ¤æ–­æ‚£è€…æ•°é‡ï¼ˆæ ¹æ®æ–‡ç« å®é™…å†…å®¹ï¼‰:
   - single: å•ä¸ªå¯è¯†åˆ«æ‚£è€…çš„ç—…ä¾‹æŠ¥å‘Š
   - multiple: å¤šæ‚£è€…ç ”ç©¶ã€é˜Ÿåˆ—ç ”ç©¶
   - mixed: åŒæ—¶æœ‰å•æ‚£è€…ç—…ä¾‹å’Œå¤šæ‚£è€…æ•°æ®
   - unknown: æ— æ˜ç¡®æ‚£è€…ä¿¡æ¯

åˆ†ç±»é€»è¾‘è¯´æ˜:
- Rejection: ç¼ºå°‘drugæˆ–AEä»»æ„ä¸€ä¸ªè¦ç´ 
- ICSR: (drug+AE+å› æœå…³ç³»+å•æ‚£è€…) OR (drug+ç‰¹æ®Šæƒ…å†µ+å•æ‚£è€…)
- Multiple_Patients: (drug+AE+å› æœå…³ç³»+å¤šæ‚£è€…) OR (drug+ç‰¹æ®Šæƒ…å†µ+å¤šæ‚£è€…)
- ICSR+Multiple_Patients: åŒæ—¶æ»¡è¶³ICSRå’ŒMultiple_Patients
- Other_Safety_Signal: å…¶ä»–æƒ…å†µåˆç­›ä¸ºsignal

ç½®ä¿¡åº¦è¯„åˆ†:
0.90-1.0: æ‰€æœ‰å­—æ®µéƒ½æœ‰æ˜ç¡®è¯æ®
0.75-0.89: ä¸»è¦å­—æ®µæ¸…æ™°
0.60-0.74: éƒ¨åˆ†å­—æ®µæ¨¡ç³Š
<0.60: è¯æ®ä¸è¶³

æ–‡ç« å†…å®¹:
---
{truncate_text(text)}
---

è¿”å›JSONæ ¼å¼:
{{
  "has_drug": boolean,
  "has_drug_reasoning": "åˆ¤æ–­ç†ç”±ï¼šä¸ºä½•è®¤ä¸ºæœ‰/æ— ç›®æ ‡è¯ºåè¯ç‰©",
  "has_ae": boolean,
  "has_ae_reasoning": "åˆ¤æ–­ç†ç”±ï¼šä¸ºä½•è®¤ä¸ºæœ‰/æ— ä¸è‰¯äº‹ä»¶æè¿°",
  "has_causality": boolean,
  "has_causality_reasoning": "åˆ¤æ–­ç†ç”±ï¼šä¸ºä½•è®¤ä¸ºæœ‰/æ— å› æœå…³ç³»è¡¨è¿°",
  "has_special_situation": boolean,
  "has_special_reasoning": "åˆ¤æ–­ç†ç”±ï¼šä¸ºä½•è®¤ä¸ºæœ‰/æ— ç‰¹æ®Šæƒ…å†µ",
  "patient_mode": "single|multiple|mixed|unknown",
  "patient_reasoning": "åˆ¤æ–­ç†ç”±ï¼šä¸ºä½•åˆ¤å®šä¸ºè¯¥æ‚£è€…æ¨¡å¼",
  "patient_max_n": integer or null,
  "confidence": 0.0-1.0,
  "reasoning": "æ•´ä½“åˆ†ææ€»ç»“",
  "evidence": {{
    "drug": ["åŸæ–‡ä¸­æåŠè¯ç‰©çš„è¯æ®"],
    "ae": ["åŸæ–‡ä¸­ä¸è‰¯äº‹ä»¶çš„æè¿°"],
    "causality": ["åŸæ–‡ä¸­å› æœå…³ç³»çš„è¡¨è¿°"],
    "special_situation": ["åŸæ–‡ä¸­ç‰¹æ®Šæƒ…å†µçš„æè¿°"],
    "patient": ["åŸæ–‡ä¸­æ‚£è€…ä¿¡æ¯çš„æè¿°ï¼ŒåŒ…æ‹¬æ•°é‡åˆ¤æ–­ä¾æ®"]
  }}
}}"""

    try:
        # ä½¿ç”¨ä¸“é—¨çš„åˆ†ç±»æ¨¡å‹é…ç½®ï¼Œé»˜è®¤ gpt-4o
        model = os.getenv("CLASSIFY_MODEL_NAME", "gpt-4o")
        # o1/o3 models don't support temperature parameter
        is_reasoning_model = model.startswith("o1") or model.startswith("o3")

        create_kwargs = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
        }

        # Only set temperature for non-reasoning models
        if not is_reasoning_model:
            create_kwargs["temperature"] = 0
            create_kwargs["response_format"] = {"type": "json_object"}

        response = client.chat.completions.create(**create_kwargs)

        content = response.choices[0].message.content or "{}"
        obj = json.loads(content)

        # Extract fields
        has_drug = bool(obj.get("has_drug", False))
        has_ae = bool(obj.get("has_ae", False))
        has_causality = bool(obj.get("has_causality", False))
        has_special = bool(obj.get("has_special_situation", False))

        patient_mode = str(obj.get("patient_mode", "unknown")).lower()
        if patient_mode not in PATIENT_MODES:
            patient_mode = "unknown"

        patient_max_n = obj.get("patient_max_n")
        if patient_max_n is not None:
            try:
                patient_max_n = int(patient_max_n)
            except (ValueError, TypeError):
                patient_max_n = None

        confidence = float(obj.get("confidence", 0.5))
        confidence = max(0.0, min(1.0, confidence))

        # Apply rule-based classification
        label = classify_by_rules(has_drug, has_ae, has_causality, has_special, patient_mode)

        # Extract evidence
        evidence = obj.get("evidence", {}) or {}
        drug_evidence = evidence.get("drug", []) or []
        ae_evidence = evidence.get("ae", []) or []
        causality_evidence = evidence.get("causality", []) or []
        special_evidence = evidence.get("special_situation", []) or []
        patient_evidence = evidence.get("patient", []) or []

        # Extract per-field reasoning
        has_drug_reasoning = obj.get("has_drug_reasoning", "")
        has_ae_reasoning = obj.get("has_ae_reasoning", "")
        has_causality_reasoning = obj.get("has_causality_reasoning", "")
        has_special_reasoning = obj.get("has_special_reasoning", "")
        patient_reasoning = obj.get("patient_reasoning", "")

        return ClassificationResult(
            filename=filename,
            label=label,
            label_cn=SAFETY_LABELS.get(label, "æœªçŸ¥"),
            has_drug=has_drug,
            has_ae=has_ae,
            has_causality=has_causality,
            has_special_situation=has_special,
            patient_mode=patient_mode,
            patient_max_n=patient_max_n,
            confidence=confidence,
            drug_evidence=drug_evidence[:5],
            ae_evidence=ae_evidence[:5],
            causality_evidence=causality_evidence[:5],
            special_evidence=special_evidence[:5],
            patient_evidence=patient_evidence[:5],
            has_drug_reasoning=has_drug_reasoning,
            has_ae_reasoning=has_ae_reasoning,
            has_causality_reasoning=has_causality_reasoning,
            has_special_reasoning=has_special_reasoning,
            patient_reasoning=patient_reasoning,
            reasoning=obj.get("reasoning", ""),
            needs_review=confidence < 0.65,
            extract_method="",
            text_length=len(text),
        )

    except json.JSONDecodeError as e:
        return ClassificationResult(
            filename=filename, label="Error", label_cn="é”™è¯¯",
            has_drug=False, has_ae=False, has_causality=False, has_special_situation=False,
            patient_mode="unknown", patient_max_n=None, confidence=0.0,
            drug_evidence=[], ae_evidence=[], causality_evidence=[],
            special_evidence=[], patient_evidence=[],
            has_drug_reasoning="", has_ae_reasoning="", has_causality_reasoning="",
            has_special_reasoning="", patient_reasoning="", reasoning="",
            needs_review=True, extract_method="", text_length=len(text),
            error=f"JSON parse error: {e}"
        )
    except Exception as e:
        return ClassificationResult(
            filename=filename, label="Error", label_cn="é”™è¯¯",
            has_drug=False, has_ae=False, has_causality=False, has_special_situation=False,
            patient_mode="unknown", patient_max_n=None, confidence=0.0,
            drug_evidence=[], ae_evidence=[], causality_evidence=[],
            special_evidence=[], patient_evidence=[],
            has_drug_reasoning="", has_ae_reasoning="", has_causality_reasoning="",
            has_special_reasoning="", patient_reasoning="", reasoning="",
            needs_review=True, extract_method="", text_length=len(text),
            error=str(e)
        )


def critique_classification(
    initial_result: ClassificationResult,
    text: str,
    article_type: str,
    filename: str = ""
) -> ClassificationResult:
    """
    Self-Critique å±‚ï¼šå®¡è§†åˆæ­¥åˆ¤æ–­ï¼Œå‘ç°å¹¶ä¿®æ­£å¸¸è§é”™è¯¯ã€‚

    æ”¯æŒäº”ç§å®¡æ ¸æ¨¡å¼ï¼š
    1. has_ae è¿‡äºå®½æ¾ï¼šç»¼è¿°/åŠ¨ç‰©å®éªŒä¸­çš„AEè¯¯åˆ¤
    2. has_ae è¿‡äºä¸¥æ ¼ï¼šç—…ä¾‹/ä¸´åºŠç ”ç©¶ä¸­é—æ¼éšå«AE
    3. has_causality è¿‡äºä¸¥æ ¼ï¼šç—…ä¾‹æŠ¥å‘Š/ä¸´åºŠç ”ç©¶ä¸­çš„éšå«å› æœè¢«é—æ¼
    4. has_special_situation è¿‡äºä¸¥æ ¼ï¼šé—æ¼è¯ç‰©æ— æ•ˆã€å„¿ç«¥ç”¨è¯ã€å¦Šå¨ æš´éœ²ç­‰ç‰¹æ®Šæƒ…å†µ
    5. patient_mode æ¡ˆä¾‹åˆ†äº«è¯¯åˆ¤ï¼šå°†"æ¡ˆä¾‹åˆ†äº«"ç±»æ–‡çŒ®è¯¯åˆ¤ä¸ºmultiple
    """
    # æ–‡ç« ç±»å‹ä¸­æ–‡æ˜ å°„
    type_cn_map = {
        'review': 'ç»¼è¿°/æŒ‡å—',
        'animal_study': 'åŠ¨ç‰©å®éªŒ',
        'case_report': 'ç—…ä¾‹æŠ¥å‘Š',
        'clinical_study': 'ä¸´åºŠç ”ç©¶',
        'unknown': 'æœªçŸ¥'
    }
    article_type_cn = type_cn_map.get(article_type, article_type)

    # ç¡®å®šå®¡æ ¸æ¨¡å¼
    critique_modes = []

    # æ¨¡å¼1: has_ae å¯èƒ½è¿‡äºå®½æ¾ï¼ˆç»¼è¿°/åŠ¨ç‰©å®éªŒä¸­è¯¯åˆ¤AEï¼‰
    if initial_result.has_ae and article_type in ['review', 'animal_study']:
        critique_modes.append('ae_too_loose')

    # æ¨¡å¼2: has_causality å¯èƒ½è¿‡äºä¸¥æ ¼ï¼ˆç—…ä¾‹/ä¸´åºŠç ”ç©¶ä¸­é—æ¼éšå«å› æœï¼‰
    # ä¿®å¤ï¼šç§»é™¤ has_ae å‰ç½®æ¡ä»¶ï¼Œå› ä¸º ae_too_strict å¯èƒ½ä¼šä¿®æ­£ has_ae
    # è®©å› æœå®¡æ ¸ç‹¬ç«‹äº AE åˆ¤æ–­
    if (initial_result.has_drug and
        not initial_result.has_causality and
        article_type in ['case_report', 'clinical_study']):
        critique_modes.append('causality_too_strict')

    # æ¨¡å¼3: has_special_situation å¯èƒ½è¿‡äºä¸¥æ ¼ï¼ˆé—æ¼ç‰¹æ®Šæƒ…å†µï¼‰
    # è§¦å‘æ¡ä»¶ï¼šæœ‰è¯ç‰©ä½†æ— ç‰¹æ®Šæƒ…å†µï¼Œä¸”æ–‡æœ¬ä¸­å¯èƒ½åŒ…å«ç‰¹æ®Šæƒ…å†µå…³é”®è¯
    if (initial_result.has_drug and
        not initial_result.has_special_situation and
        article_type in ['case_report', 'clinical_study']):
        # æ£€æŸ¥æ˜¯å¦å¯èƒ½å­˜åœ¨ç‰¹æ®Šæƒ…å†µå…³é”®è¯
        special_keywords = [
            'æ— æ•ˆ', 'ç–—æ•ˆä¸ä½³', 'æ²»ç–—å¤±è´¥', 'æœªèƒ½æ§åˆ¶', 'æ§åˆ¶ä¸ä½³', 'ç—…æƒ…æœªæ”¹å–„',
            'æ¢è¯', 'åœè¯', 'æ›´æ¢', 'è°ƒæ•´æ–¹æ¡ˆ',
            'å„¿ç«¥', 'å°å„¿', 'æ‚£å„¿', 'å©´å„¿', 'å¹¼å„¿', 'æ–°ç”Ÿå„¿', 'é’å°‘å¹´',
            'å¦Šå¨ ', 'å­•å¦‡', 'æ€€å­•', 'å“ºä¹³', 'æ¯ä¹³', 'äº§å¦‡',
            'è¿‡é‡', 'ä¸­æ¯’', 'è¶…å‰‚é‡',
            'ç”¨è¯é”™è¯¯', 'ç»™è¯é”™è¯¯', 'å‰‚é‡é”™è¯¯',
            'è”åˆç”¨è¯', 'è¯ç‰©ç›¸äº’ä½œç”¨', 'åˆç”¨', 'é…ä¼',
            'è¶…è¯´æ˜ä¹¦', 'è¶…é€‚åº”ç—‡', 'off-label',
        ]
        text_lower = text.lower()
        if any(kw in text_lower for kw in special_keywords):
            critique_modes.append('special_too_strict')

    # æ¨¡å¼4: has_ae å¯èƒ½è¿‡äºä¸¥æ ¼ï¼ˆé—æ¼ä¸´åºŠç ”ç©¶ä¸­çš„éšå«AEï¼‰
    # è§¦å‘æ¡ä»¶ï¼šhas_ae=False + ç—…ä¾‹/ä¸´åºŠç ”ç©¶ + æœ‰è¯ç‰© + æ–‡ä¸­å«AEç›¸å…³å…³é”®è¯
    if (initial_result.has_drug and
        not initial_result.has_ae and
        article_type in ['case_report', 'clinical_study']):
        ae_hint_keywords = [
            'ä¸è‰¯ååº”', 'è®°å½•', 'è§‚å¯Ÿ', 'ç›‘æµ‹', 'å®‰å…¨æ€§',
            'æœç”¨', 'å£æœ', 'ç”¨è¯', 'æ²»ç–—æœŸé—´'
        ]
        text_lower = text.lower()
        if any(kw in text_lower for kw in ae_hint_keywords):
            critique_modes.append('ae_too_strict')

    # æ¨¡å¼5: patient_mode "æ¡ˆä¾‹åˆ†äº«"è¯¯åˆ¤ï¼ˆå°†æ¡ˆä¾‹åˆ†äº«è¯¯åˆ¤ä¸ºmultipleï¼‰
    # è§¦å‘æ¡ä»¶ï¼špatient_mode=multiple + æ–‡ä»¶åæˆ–æ­£æ–‡å«"æ¡ˆä¾‹åˆ†äº«"
    if initial_result.patient_mode == 'multiple':
        case_sharing_keywords = ['æ¡ˆä¾‹åˆ†äº«', 'ç—…ä¾‹åˆ†äº«', 'ç—…æ¡ˆåˆ†äº«', 'æ¡ˆä¾‹ä¸¾éš…', 'ç—…æ¡ˆä¸¾éš…']
        text_lower = text.lower()
        filename_lower = filename.lower()
        if (any(kw in text_lower for kw in case_sharing_keywords) or
            any(kw in filename_lower for kw in case_sharing_keywords)):
            critique_modes.append('patient_mode_case_sharing')

    if not critique_modes:
        return initial_result

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return initial_result

    client = OpenAI(api_key=api_key)
    result = initial_result

    # ä¾æ¬¡æ‰§è¡Œæ¯ç§å®¡æ ¸æ¨¡å¼
    for mode in critique_modes:
        if mode == 'ae_too_loose':
            result = _critique_ae_too_loose(client, result, text, article_type_cn)
        elif mode == 'causality_too_strict':
            result = _critique_causality_too_strict(client, result, text, article_type_cn)
        elif mode == 'special_too_strict':
            result = _critique_special_too_strict(client, result, text, article_type_cn)
        elif mode == 'ae_too_strict':
            result = _critique_ae_too_strict(client, result, text, article_type_cn)
        elif mode == 'patient_mode_case_sharing':
            result = _critique_patient_mode_case_sharing(client, result, text, filename)

    return result


def _critique_ae_too_loose(
    client,
    initial_result: ClassificationResult,
    text: str,
    article_type_cn: str
) -> ClassificationResult:
    """å®¡æ ¸ has_ae æ˜¯å¦è¿‡äºå®½æ¾ï¼ˆç»¼è¿°/åŠ¨ç‰©å®éªŒè¯¯åˆ¤ï¼‰"""

    critique_prompt = f"""ä½ æ˜¯è¯ç‰©å®‰å…¨åˆ†ç±»å®¡æ ¸ä¸“å®¶ã€‚è¯·å®¡è§†ä»¥ä¸‹åˆ†ç±»åˆ¤æ–­æ˜¯å¦å­˜åœ¨å¸¸è§é”™è¯¯ã€‚

## åˆæ­¥åˆ¤æ–­
- has_ae: {initial_result.has_ae}
- has_ae_reasoning: {initial_result.has_ae_reasoning}
- æ–‡ç« ç±»å‹: {article_type_cn}

## éœ€æ£€æŸ¥çš„å¸¸è§é”™è¯¯
1. ã€ç»¼è¿°è¯¯åˆ¤ã€‘ç»¼è¿°/æŒ‡å—ä¸­ä»…æ³›æ³›è®¨è®ºè¯ç‰©å¯èƒ½çš„å‰¯ä½œç”¨ï¼ˆå¦‚"è¯¥è¯ç‰©å¯èƒ½å¯¼è‡´XX"ï¼‰ï¼Œæ— å…·ä½“ç—…ä¾‹æŠ¥å‘Šï¼Œä¸åº”åˆ¤å®š has_ae=True
2. ã€åŠ¨ç‰©å®éªŒã€‘çº¯åŠ¨ç‰©å®éªŒä¸­çš„æ¯’æ€§ååº”ï¼ˆå¦‚å¤§é¼ è‚æŸä¼¤ï¼‰ä¸ç®—äººä½“AEï¼Œä¸åº”åˆ¤å®š has_ae=True
3. ã€ç–¾ç—…ç—‡çŠ¶ã€‘ç–¾ç—…æœ¬èº«çš„ç—‡çŠ¶ï¼ˆå¦‚ç¥ç»å†…åˆ†æ³Œè‚¿ç˜¤çš„è…¹æ³»ã€æ½®çº¢ï¼‰ä¸æ˜¯è¯ç‰©AE

## ç›¸å…³åŸæ–‡ç‰‡æ®µ
{text[:4000]}

## è¯·åˆ¤æ–­
1. åˆæ­¥åˆ¤æ–­æ˜¯å¦å­˜åœ¨ä¸Šè¿°é”™è¯¯ï¼Ÿ
2. å¦‚å­˜åœ¨é”™è¯¯ï¼Œhas_ae åº”è¯¥ä¿®æ­£ä¸ºä»€ä¹ˆï¼Ÿ
3. ç»™å‡ºä¿®æ­£ç†ç”±ã€‚

è¿”å›JSON:
{{
    "has_error": boolean,
    "corrected_has_ae": boolean,
    "correction_reasoning": "ä¿®æ­£ç†ç”±"
}}"""

    try:
        model = os.getenv("CLASSIFY_MODEL_NAME", "gpt-4o")
        is_reasoning_model = model.startswith("o1") or model.startswith("o3")

        create_kwargs = {
            "model": model,
            "messages": [{"role": "user", "content": critique_prompt}],
        }

        if not is_reasoning_model:
            create_kwargs["temperature"] = 0
            create_kwargs["response_format"] = {"type": "json_object"}

        response = client.chat.completions.create(**create_kwargs)
        content = response.choices[0].message.content or "{}"
        critique_result = json.loads(content)

        if critique_result.get("has_error"):
            corrected_has_ae = critique_result.get("corrected_has_ae", False)
            correction_reasoning = critique_result.get("correction_reasoning", "")

            # é‡æ–°åº”ç”¨è§„åˆ™åˆ¤æ–­
            new_label = classify_by_rules(
                initial_result.has_drug,
                corrected_has_ae,
                initial_result.has_causality,
                initial_result.has_special_situation,
                initial_result.patient_mode
            )

            return replace(
                initial_result,
                has_ae=corrected_has_ae,
                has_ae_reasoning=f"{initial_result.has_ae_reasoning}\n[Self-Critique:AEä¿®æ­£]: {correction_reasoning}",
                label=new_label,
                label_cn=SAFETY_LABELS.get(new_label, "æœªçŸ¥")
            )

    except Exception as e:
        print(f"      âš ï¸ Self-Critique (AE) error: {e}")

    return initial_result


def _critique_causality_too_strict(
    client,
    initial_result: ClassificationResult,
    text: str,
    article_type_cn: str
) -> ClassificationResult:
    """å®¡æ ¸ has_causality æ˜¯å¦è¿‡äºä¸¥æ ¼ï¼ˆç—…ä¾‹/ä¸´åºŠç ”ç©¶ä¸­é—æ¼éšå«å› æœï¼‰"""

    critique_prompt = f"""ä½ æ˜¯è¯ç‰©å®‰å…¨åˆ†ç±»å®¡æ ¸ä¸“å®¶ã€‚è¯·å®¡è§†ä»¥ä¸‹åˆ†ç±»åˆ¤æ–­æ˜¯å¦é—æ¼äº†æ–‡ç« ä¸­çš„å› æœå…³ç³»è¯æ®ã€‚

## åˆæ­¥åˆ¤æ–­
- has_ae: {initial_result.has_ae}
- has_causality: {initial_result.has_causality}
- has_causality_reasoning: {initial_result.has_causality_reasoning}
- æ–‡ç« ç±»å‹: {article_type_cn}

## é‡è¦åŸåˆ™
has_causality çš„åˆ¤æ–­ç›®çš„æ˜¯ç¡®å®šæ–‡ç« æ˜¯å¦åŒ…å«è¯ç‰©-AEå› æœåˆ†æä¿¡æ¯ï¼Œç”¨äºè¯ç‰©è­¦æˆ’æ–‡çŒ®ç­›é€‰ï¼š
- âš ï¸ å³ä½¿AEæ˜¯ç”±æ–‡ä¸­å…¶ä»–è¯ç‰©ï¼ˆéç›®æ ‡ç›‘æµ‹è¯ç‰©ï¼‰å¼•èµ·çš„ï¼Œåªè¦æ–‡ç« åŒ…å«æ˜ç¡®çš„è¯ç‰©-AEå› æœå…³ç³»è¡¨è¿°ï¼Œhas_causalityä»åº”ä¸ºTrue
- è¿™æ ·åšæ˜¯ä¸ºäº†ç¡®ä¿åŒ…å«å®‰å…¨æ€§ä¿¡æ¯çš„æ–‡çŒ®èƒ½è¢«æ­£ç¡®æ ‡è®°ï¼Œä¾›äººå·¥å®¡æ ¸

## éœ€æ£€æŸ¥çš„é—æ¼æƒ…å†µ
åœ¨ç—…ä¾‹æŠ¥å‘Šæˆ–ä¸´åºŠç ”ç©¶ä¸­ï¼Œä»¥ä¸‹æƒ…å†µåº”è§†ä¸ºå­˜åœ¨å› æœå…³ç³»ï¼ˆhas_causality=Trueï¼‰ï¼š

1. ã€æ˜ç¡®å½’å› ã€‘æ–‡ç« ä¸­ä»»ä½•è¯ç‰©è¢«æ˜ç¡®å½’å› ä¸ºAEçš„åŸå› ï¼ˆå¦‚"Xè¯å¯¼è‡´Yç—‡çŠ¶"ã€"Yç”±Xå¼•èµ·"ï¼‰
2. ã€ç—…ä¾‹æŠ¥å‘Šå› æœã€‘ç—…ä¾‹æŠ¥å‘Šä¸­æè¿°"ç”¨è¯åå‡ºç°XXç—‡çŠ¶"ï¼Œå³ä½¿æœªæ˜ç¡®è¯´"å¯¼è‡´"ï¼Œä¹Ÿåº”è§†ä¸ºå­˜åœ¨å› æœ
3. ã€ä¸´åºŠç ”ç©¶AEã€‘ä¸´åºŠç ”ç©¶/è¯•éªŒä¸­è®°å½•çš„ä¸è‰¯ååº”å‘ç”Ÿç‡ï¼ˆå¦‚"æ²»ç–—ç»„ä¸è‰¯ååº”å‘ç”Ÿç‡15%"ï¼‰ï¼Œåº”è§†ä¸ºå­˜åœ¨éšå«å› æœ
4. ã€æ—¶é—´å…³è”ã€‘æ˜ç¡®çš„æ—¶é—´å…³è”è¡¨è¿°ï¼ˆå¦‚"æœè¯3å¤©åå‡ºç°"ã€"æ²»ç–—æœŸé—´å‘ç”Ÿ"ï¼‰åº”è§†ä¸ºå› æœè¯æ®
5. ã€å»æ¿€å‘/å†æ¿€å‘ã€‘åœè¯åç—‡çŠ¶ç¼“è§£ã€å†ç”¨è¯åå¤å‘ï¼Œæ˜¯å¼ºå› æœè¯æ®

## ç›¸å…³åŸæ–‡ç‰‡æ®µ
{text[:4000]}

## è¯·åˆ¤æ–­
1. æ–‡ç« ä¸­æ˜¯å¦å­˜åœ¨ä»»ä½•è¯ç‰©-AEå› æœå…³ç³»çš„è¡¨è¿°ï¼ˆä¸é™äºç›®æ ‡è¯ç‰©ï¼‰ï¼Ÿ
2. å¦‚æœåˆæ­¥åˆ¤æ–­é—æ¼äº†å› æœå…³ç³»ï¼Œhas_causality åº”è¯¥ä¿®æ­£ä¸ºTrue
3. ç»™å‡ºä¿®æ­£ç†ç”±å’Œå…·ä½“è¯æ®ã€‚

è¿”å›JSON:
{{
    "has_error": boolean,
    "corrected_has_causality": boolean,
    "correction_reasoning": "ä¿®æ­£ç†ç”±"
}}"""

    try:
        model = os.getenv("CLASSIFY_MODEL_NAME", "gpt-4o")
        is_reasoning_model = model.startswith("o1") or model.startswith("o3")

        create_kwargs = {
            "model": model,
            "messages": [{"role": "user", "content": critique_prompt}],
        }

        if not is_reasoning_model:
            create_kwargs["temperature"] = 0
            create_kwargs["response_format"] = {"type": "json_object"}

        response = client.chat.completions.create(**create_kwargs)
        content = response.choices[0].message.content or "{}"
        critique_result = json.loads(content)

        if critique_result.get("has_error"):
            corrected_has_causality = critique_result.get("corrected_has_causality", True)
            correction_reasoning = critique_result.get("correction_reasoning", "")

            # é‡æ–°åº”ç”¨è§„åˆ™åˆ¤æ–­
            new_label = classify_by_rules(
                initial_result.has_drug,
                initial_result.has_ae,
                corrected_has_causality,
                initial_result.has_special_situation,
                initial_result.patient_mode
            )

            return replace(
                initial_result,
                has_causality=corrected_has_causality,
                has_causality_reasoning=f"{initial_result.has_causality_reasoning}\n[Self-Critique:å› æœä¿®æ­£]: {correction_reasoning}",
                label=new_label,
                label_cn=SAFETY_LABELS.get(new_label, "æœªçŸ¥")
            )

    except Exception as e:
        print(f"      âš ï¸ Self-Critique (Causality) error: {e}")

    return initial_result


def _critique_special_too_strict(
    client,
    initial_result: ClassificationResult,
    text: str,
    article_type_cn: str
) -> ClassificationResult:
    """å®¡æ ¸ has_special_situation æ˜¯å¦è¿‡äºä¸¥æ ¼ï¼ˆé—æ¼ç‰¹æ®Šæƒ…å†µï¼‰"""

    critique_prompt = f"""ä½ æ˜¯è¯ç‰©å®‰å…¨åˆ†ç±»å®¡æ ¸ä¸“å®¶ã€‚è¯·å®¡è§†ä»¥ä¸‹åˆ†ç±»åˆ¤æ–­æ˜¯å¦é—æ¼äº†ç‰¹æ®Šæƒ…å†µã€‚

## åˆæ­¥åˆ¤æ–­
- has_drug: {initial_result.has_drug}
- has_special_situation: {initial_result.has_special_situation}
- has_special_reasoning: {initial_result.has_special_reasoning}
- æ–‡ç« ç±»å‹: {article_type_cn}

## éœ€æ£€æŸ¥çš„ç‰¹æ®Šæƒ…å†µï¼ˆä»»ä¸€å­˜åœ¨å³åº”åˆ¤å®š has_special_situation=Trueï¼‰

1. ã€è¯ç‰©æ— æ•ˆ/ç–—æ•ˆä¸ä½³ã€‘âš ï¸ è¿™æ˜¯æœ€å¸¸é—æ¼çš„ç‰¹æ®Šæƒ…å†µ
   - å…³é”®è¯ï¼š"æ— æ•ˆ"ã€"ç–—æ•ˆä¸ä½³"ã€"æ²»ç–—å¤±è´¥"ã€"æœªèƒ½æ§åˆ¶"ã€"æ§åˆ¶ä¸ä½³"ã€"ç—…æƒ…æœªæ”¹å–„"
   - å…³é”®è¯ï¼š"æ¢è¯"ã€"æ›´æ¢æ²»ç–—æ–¹æ¡ˆ"ã€"è°ƒæ•´ç”¨è¯"ã€"æ•ˆæœæ¬ ä½³"
   - æ³¨æ„ï¼šå³ä½¿æ–‡ç« ä¸»é¢˜ä¸æ˜¯è®¨è®ºè¯ç‰©æ— æ•ˆï¼Œåªè¦æåˆ°ç›®æ ‡è¯ç‰©"æ— æ•ˆ/å¤±è´¥"å°±ç®—

2. ã€å„¿ç«¥ç”¨è¯ã€‘
   - æ‚£è€…ä¸ºå„¿ç«¥ã€å©´å¹¼å„¿ã€é’å°‘å¹´ï¼ˆ<18å²ï¼‰
   - å…³é”®è¯ï¼š"æ‚£å„¿"ã€"å°å„¿"ã€"å„¿ç«¥"ã€"å©´å„¿"ã€"å¹¼å„¿"ã€"æ–°ç”Ÿå„¿"

3. ã€å¦Šå¨ /å“ºä¹³æœŸæš´éœ²ã€‘
   - æ‚£è€…ä¸ºå­•å¦‡æˆ–å“ºä¹³æœŸå¦‡å¥³
   - å…³é”®è¯ï¼š"å¦Šå¨ "ã€"å­•å¦‡"ã€"æ€€å­•"ã€"å“ºä¹³"ã€"æ¯ä¹³"ã€"äº§å¦‡"

4. ã€è¿‡é‡/ä¸­æ¯’ã€‘
   - è¯ç‰©è¿‡é‡ä½¿ç”¨æˆ–ä¸­æ¯’
   - å…³é”®è¯ï¼š"è¿‡é‡"ã€"ä¸­æ¯’"ã€"è¶…å‰‚é‡"

5. ã€ç”¨è¯é”™è¯¯ã€‘
   - ç»™è¯é”™è¯¯ã€å‰‚é‡é”™è¯¯ã€ç”¨æ³•é”™è¯¯
   - å…³é”®è¯ï¼š"ç”¨è¯é”™è¯¯"ã€"ç»™è¯é”™è¯¯"ã€"å‰‚é‡é”™è¯¯"

6. ã€è¯ç‰©ç›¸äº’ä½œç”¨ã€‘
   - ä¸å…¶ä»–è¯ç‰©çš„ç›¸äº’ä½œç”¨å¯¼è‡´é—®é¢˜
   - å…³é”®è¯ï¼š"è¯ç‰©ç›¸äº’ä½œç”¨"ã€"è”åˆç”¨è¯ä¸è‰¯ååº”"

7. ã€è¶…è¯´æ˜ä¹¦ç”¨è¯ã€‘
   - è¶…é€‚åº”ç—‡ã€è¶…å‰‚é‡ã€è¶…äººç¾¤ä½¿ç”¨
   - å…³é”®è¯ï¼š"è¶…è¯´æ˜ä¹¦"ã€"è¶…é€‚åº”ç—‡"ã€"off-label"

## ç›¸å…³åŸæ–‡ç‰‡æ®µ
{text[:4000]}

## è¯·åˆ¤æ–­
1. åˆæ­¥åˆ¤æ–­æ˜¯å¦é—æ¼äº†ä¸Šè¿°ä»»ä¸€ç‰¹æ®Šæƒ…å†µï¼Ÿ
2. å¦‚æœ‰é—æ¼ï¼Œhas_special_situation åº”è¯¥ä¿®æ­£ä¸ºä»€ä¹ˆï¼Ÿ
3. ç»™å‡ºä¿®æ­£ç†ç”±å’Œå…·ä½“è¯æ®ã€‚

è¿”å›JSON:
{{
    "has_error": boolean,
    "corrected_has_special": boolean,
    "correction_reasoning": "ä¿®æ­£ç†ç”±ï¼ŒåŒ…æ‹¬å…·ä½“æ˜¯å“ªç§ç‰¹æ®Šæƒ…å†µ"
}}"""

    try:
        model = os.getenv("CLASSIFY_MODEL_NAME", "gpt-4o")
        is_reasoning_model = model.startswith("o1") or model.startswith("o3")

        create_kwargs = {
            "model": model,
            "messages": [{"role": "user", "content": critique_prompt}],
        }

        if not is_reasoning_model:
            create_kwargs["temperature"] = 0
            create_kwargs["response_format"] = {"type": "json_object"}

        response = client.chat.completions.create(**create_kwargs)
        content = response.choices[0].message.content or "{}"
        critique_result = json.loads(content)

        if critique_result.get("has_error"):
            corrected_has_special = critique_result.get("corrected_has_special", True)
            correction_reasoning = critique_result.get("correction_reasoning", "")

            # é‡æ–°åº”ç”¨è§„åˆ™åˆ¤æ–­
            new_label = classify_by_rules(
                initial_result.has_drug,
                initial_result.has_ae,
                initial_result.has_causality,
                corrected_has_special,
                initial_result.patient_mode
            )

            return replace(
                initial_result,
                has_special_situation=corrected_has_special,
                has_special_reasoning=f"{initial_result.has_special_reasoning}\n[Self-Critique:ç‰¹æ®Šæƒ…å†µä¿®æ­£]: {correction_reasoning}",
                label=new_label,
                label_cn=SAFETY_LABELS.get(new_label, "æœªçŸ¥")
            )

    except Exception as e:
        print(f"      âš ï¸ Self-Critique (Special) error: {e}")

    return initial_result


def _critique_ae_too_strict(
    client,
    initial_result: ClassificationResult,
    text: str,
    article_type_cn: str
) -> ClassificationResult:
    """å®¡æ ¸ has_ae æ˜¯å¦è¿‡äºä¸¥æ ¼ï¼ˆé—æ¼äº†ä¸´åºŠç ”ç©¶ä¸­çš„éšå«AEï¼‰"""

    critique_prompt = f"""ä½ æ˜¯è¯ç‰©å®‰å…¨åˆ†ç±»å®¡æ ¸ä¸“å®¶ã€‚è¯·å®¡è§†ä»¥ä¸‹åˆ†ç±»åˆ¤æ–­æ˜¯å¦é—æ¼äº†éšå«çš„ä¸è‰¯äº‹ä»¶ä¿¡æ¯ã€‚

## åˆæ­¥åˆ¤æ–­
- has_drug: {initial_result.has_drug}
- has_ae: {initial_result.has_ae} (å½“å‰åˆ¤æ–­ä¸ºFalse)
- has_ae_reasoning: {initial_result.has_ae_reasoning}
- æ–‡ç« ç±»å‹: {article_type_cn}

## éœ€æ£€æŸ¥çš„é—æ¼æƒ…å†µ

1. ã€ä¸´åºŠç ”ç©¶éšå«AEã€‘
   - å¦‚æœæ˜¯ä¸´åºŠç ”ç©¶/å¯¹ç…§ç ”ç©¶ï¼Œä¸”"ä¸è‰¯ååº”"ä½œä¸ºè§‚å¯ŸæŒ‡æ ‡
   - å…³é”®è¯ï¼š"è®°å½•ä¸è‰¯ååº”"ã€"è§‚å¯Ÿä¸è‰¯ååº”"ã€"ä¸è‰¯ååº”å‘ç”Ÿç‡"
   - å…³é”®è¯ï¼š"ä¸¤ç»„ä¸è‰¯ååº”æ¯”è¾ƒ"ã€"æ²»ç–—ç»„vså¯¹ç…§ç»„"
   - å³ä½¿å…¨æ–‡æœªè¯¦ç»†åˆ—å‡ºAEï¼Œç ”ç©¶è®¾è®¡æœ¬èº«éšå«äº†AEç›‘æµ‹

2. ã€ç—…ä¾‹æŠ¥å‘ŠèƒŒæ™¯ç”¨è¯ã€‘
   - ç—…ä¾‹æŠ¥å‘Šä¸­æ‚£è€…æœ‰æ˜ç¡®çš„ç›®æ ‡è¯ç‰©ç”¨è¯è®°å½•
   - å³ä½¿ä¸»è¦AEä¸æ˜¯ç›®æ ‡è¯ç‰©å¼•èµ·ï¼ŒèƒŒæ™¯ç”¨è¯æ„æˆå®‰å…¨ç›‘æµ‹åœºæ™¯
   - å…³é”®è¯ï¼š"æœç”¨/å£æœ[ç›®æ ‡è¯ç‰©]"ã€"æ—¢å¾€ç”¨è¯"

3. ã€æ²»ç–—æœŸé—´è§‚å¯Ÿã€‘
   - ä¸´åºŠç ”ç©¶ä¸­"æ²»ç–—æœŸé—´å¯†åˆ‡è§‚å¯Ÿ/ç›‘æµ‹"
   - éšå«äº†å¯¹æ½œåœ¨AEçš„å…³æ³¨

## ç›¸å…³åŸæ–‡ç‰‡æ®µ
{text[:4000]}

## è¯·åˆ¤æ–­
1. åˆæ­¥åˆ¤æ–­æ˜¯å¦é—æ¼äº†ä¸Šè¿°ä»»ä¸€éšå«AEæƒ…å†µï¼Ÿ
2. å¦‚æœ‰é—æ¼ï¼Œhas_ae åº”è¯¥ä¿®æ­£ä¸ºä»€ä¹ˆï¼Ÿ
3. ç»™å‡ºä¿®æ­£ç†ç”±å’Œå…·ä½“è¯æ®ã€‚

è¿”å›JSON:
{{
    "has_error": boolean,
    "corrected_has_ae": boolean,
    "correction_reasoning": "ä¿®æ­£ç†ç”±"
}}"""

    try:
        model = os.getenv("CLASSIFY_MODEL_NAME", "gpt-4o")
        is_reasoning_model = model.startswith("o1") or model.startswith("o3")

        create_kwargs = {
            "model": model,
            "messages": [{"role": "user", "content": critique_prompt}],
        }

        if not is_reasoning_model:
            create_kwargs["temperature"] = 0
            create_kwargs["response_format"] = {"type": "json_object"}

        response = client.chat.completions.create(**create_kwargs)
        content = response.choices[0].message.content or "{}"
        critique_result = json.loads(content)

        if critique_result.get("has_error"):
            corrected_has_ae = critique_result.get("corrected_has_ae", True)
            correction_reasoning = critique_result.get("correction_reasoning", "")

            # é‡æ–°åº”ç”¨è§„åˆ™åˆ¤æ–­
            new_label = classify_by_rules(
                initial_result.has_drug,
                corrected_has_ae,
                initial_result.has_causality,
                initial_result.has_special_situation,
                initial_result.patient_mode
            )

            return replace(
                initial_result,
                has_ae=corrected_has_ae,
                has_ae_reasoning=f"{initial_result.has_ae_reasoning}\n[Self-Critique:AEè¿‡ä¸¥ä¿®æ­£]: {correction_reasoning}",
                label=new_label,
                label_cn=SAFETY_LABELS.get(new_label, "æœªçŸ¥")
            )

    except Exception as e:
        print(f"      âš ï¸ Self-Critique (AEè¿‡ä¸¥) error: {e}")

    return initial_result


def _critique_patient_mode_case_sharing(
    client,
    initial_result: ClassificationResult,
    text: str,
    filename: str
) -> ClassificationResult:
    """å®¡æ ¸ patient_mode æ˜¯å¦å°†"æ¡ˆä¾‹åˆ†äº«"è¯¯åˆ¤ä¸º multiple"""

    critique_prompt = f"""ä½ æ˜¯è¯ç‰©å®‰å…¨åˆ†ç±»å®¡æ ¸ä¸“å®¶ã€‚è¯·å®¡è§†æ‚£è€…æ¨¡å¼åˆ¤æ–­æ˜¯å¦æ­£ç¡®ã€‚

## åˆæ­¥åˆ¤æ–­
- patient_mode: {initial_result.patient_mode} (å½“å‰åˆ¤æ–­ä¸ºmultiple)
- patient_reasoning: {initial_result.patient_reasoning}
- æ–‡ä»¶å: {filename}

## éœ€æ£€æŸ¥çš„è¯¯åˆ¤æƒ…å†µ

**"æ¡ˆä¾‹åˆ†äº«"ç±»æ–‡çŒ®ç‰¹æ®Šè§„åˆ™**ï¼š
- å¦‚æœæ–‡ç« ç±»å‹æ˜¯"æ¡ˆä¾‹åˆ†äº«"/"ç—…ä¾‹åˆ†äº«"/"ç—…æ¡ˆåˆ†äº«"
- å³ä½¿åŒ…å«å¤šä¸ªç—…ä¾‹ï¼ˆå¦‚"ç—…æ¡ˆ1"ã€"ç—…æ¡ˆ2"ã€"æ¡ˆä¾‹ä¸€"ã€"æ¡ˆä¾‹äºŒ"ï¼‰
- æ¯ä¸ªç—…ä¾‹éƒ½æ˜¯**ç‹¬ç«‹çš„å•æ‚£è€…æŠ¥å‘Š(ICSR)**
- åº”è¯¥åˆ¤æ–­ä¸º patient_mode="single"ï¼Œè€Œé "multiple"

## åˆ¤æ–­ä¾æ®
- æ ‡é¢˜æˆ–æ­£æ–‡å«"æ¡ˆä¾‹åˆ†äº«"/"ç—…ä¾‹åˆ†äº«"/"ç—…æ¡ˆåˆ†äº«" â†’ single
- æ­£æ–‡ç»“æ„ä¸º"ç—…æ¡ˆ1...ç—…æ¡ˆ2..." â†’ å¤šä¸ªç‹¬ç«‹å•ä¾‹ï¼Œç®—single
- æ˜ç¡®æ ·æœ¬é‡"çº³å…¥XXä¾‹"å¹¶åšç»Ÿè®¡åˆ†æ â†’ æ‰æ˜¯çœŸæ­£çš„ multiple

## ç›¸å…³åŸæ–‡ç‰‡æ®µ
{text[:3000]}

## è¯·åˆ¤æ–­
1. è¯¥æ–‡çŒ®æ˜¯å¦ä¸º"æ¡ˆä¾‹åˆ†äº«"ç±»å‹ï¼Ÿ
2. å¦‚æœæ˜¯ï¼Œpatient_mode åº”è¯¥ä¿®æ­£ä¸º "single" å—ï¼Ÿ
3. ç»™å‡ºä¿®æ­£ç†ç”±ã€‚

è¿”å›JSON:
{{
    "has_error": boolean,
    "corrected_patient_mode": "single" or "multiple",
    "correction_reasoning": "ä¿®æ­£ç†ç”±"
}}"""

    try:
        model = os.getenv("CLASSIFY_MODEL_NAME", "gpt-4o")
        is_reasoning_model = model.startswith("o1") or model.startswith("o3")

        create_kwargs = {
            "model": model,
            "messages": [{"role": "user", "content": critique_prompt}],
        }

        if not is_reasoning_model:
            create_kwargs["temperature"] = 0
            create_kwargs["response_format"] = {"type": "json_object"}

        response = client.chat.completions.create(**create_kwargs)
        content = response.choices[0].message.content or "{}"
        critique_result = json.loads(content)

        if critique_result.get("has_error"):
            corrected_patient_mode = critique_result.get("corrected_patient_mode", "single")
            correction_reasoning = critique_result.get("correction_reasoning", "")

            # é‡æ–°åº”ç”¨è§„åˆ™åˆ¤æ–­
            new_label = classify_by_rules(
                initial_result.has_drug,
                initial_result.has_ae,
                initial_result.has_causality,
                initial_result.has_special_situation,
                corrected_patient_mode
            )

            return replace(
                initial_result,
                patient_mode=corrected_patient_mode,
                patient_reasoning=f"{initial_result.patient_reasoning}\n[Self-Critique:æ¡ˆä¾‹åˆ†äº«ä¿®æ­£]: {correction_reasoning}",
                label=new_label,
                label_cn=SAFETY_LABELS.get(new_label, "æœªçŸ¥")
            )

    except Exception as e:
        print(f"      âš ï¸ Self-Critique (æ¡ˆä¾‹åˆ†äº«) error: {e}")

    return initial_result


def load_drug_keywords(path: Path) -> list[str]:
    """Load drug keywords from file."""
    if not path.exists():
        return []
    keywords = []
    for line in path.read_text(encoding="utf-8", errors="ignore").splitlines():
        line = line.strip()
        if line and not line.startswith("#"):
            keywords.append(line)
    return keywords


def classify_papers(
    input_dir: Path,
    output_path: Path,
    drug_keywords: list[str],
    max_papers: int = 0,
) -> list[ClassificationResult]:
    """Classify all papers in input directory."""
    pdf_files = sorted(input_dir.glob("*.pdf"))
    total = len(pdf_files)

    if max_papers > 0:
        pdf_files = pdf_files[:max_papers]

    print(f"\nğŸ“š Classifying {len(pdf_files)} papers (from {total} total)")
    print(f"   Drug keywords: {len(drug_keywords)}")
    print("=" * 60)

    results: list[ClassificationResult] = []

    for idx, pdf_path in enumerate(pdf_files, 1):
        filename = pdf_path.name
        print(f"\n[{idx}/{len(pdf_files)}] ğŸ“„ {filename[:50]}...")

        # Extract text
        print("      Extracting text...")
        text, method = extract_pdf_text(pdf_path)

        if not text.strip():
            print("      âŒ Could not extract text")
            results.append(ClassificationResult(
                filename=filename, label="Error", label_cn="é”™è¯¯",
                has_drug=False, has_ae=False, has_causality=False, has_special_situation=False,
                patient_mode="unknown", patient_max_n=None, confidence=0.0,
                drug_evidence=[], ae_evidence=[], causality_evidence=[],
                special_evidence=[], patient_evidence=[],
                has_drug_reasoning="", has_ae_reasoning="", has_causality_reasoning="",
                has_special_reasoning="", patient_reasoning="", reasoning="",
                needs_review=True, extract_method=method, text_length=0,
                error="Text extraction failed"
            ))
            continue

        print(f"      Extracted {len(text)} chars via {method}")

        # é€‰æ‹©åˆ†ç±»æ¨¡å¼
        classify_mode = os.getenv("CLASSIFY_MODE", "default").lower()

        if classify_mode == "multi_agent" and MULTI_AGENT_AVAILABLE:
            # Multi-Agent è¾©è®ºæ¨¡å¼
            print("      ğŸ¤– Classifying with Multi-Agent debate...")
            ma_result = classify_with_multi_agent(text, filename, drug_keywords)

            # è½¬æ¢ä¸º ClassificationResult
            result = ClassificationResult(
                filename=filename,
                label=ma_result.final_label,
                label_cn=ma_result.final_label_cn,
                has_drug=ma_result.has_drug,
                has_ae=ma_result.has_ae,
                has_causality=ma_result.has_causality,
                has_special_situation=ma_result.has_special_situation,
                patient_mode=ma_result.patient_mode,
                patient_max_n=ma_result.patient_max_n,
                confidence=ma_result.confidence,
                drug_evidence=ma_result.pharmacologist.judgments.get("has_drug_evidence", []),
                ae_evidence=ma_result.pharmacologist.judgments.get("has_ae_evidence", []),
                causality_evidence=ma_result.clinician.judgments.get("causality_evidence", []),
                special_evidence=ma_result.analyst.judgments.get("special_evidence", []),
                patient_evidence=ma_result.clinician.judgments.get("patient_evidence", []),
                has_drug_reasoning=f"[è¯ç‰©å­¦ä¸“å®¶] {ma_result.pharmacologist.reasoning}",
                has_ae_reasoning=f"[è¯ç‰©å­¦ä¸“å®¶] {ma_result.pharmacologist.reasoning}",
                has_causality_reasoning=f"[ä¸´åºŠåŒ»ç”Ÿ] {ma_result.clinician.reasoning}",
                has_special_reasoning=f"[æ–‡çŒ®åˆ†æ] {ma_result.analyst.reasoning}",
                patient_reasoning=f"[ä¸´åºŠåŒ»ç”Ÿ] {ma_result.clinician.reasoning}",
                reasoning=ma_result.reasoning,
                needs_review=ma_result.needs_review,
                extract_method=method,
                text_length=len(text),
            )
        else:
            # åŸæœ‰åˆ†ç±»æ¨¡å¼
            print("      Classifying with LLM...")
            result = classify_with_openai(text, filename, drug_keywords)
            result.extract_method = method

            # Self-Critique å±‚ï¼ˆå¯é€‰ï¼Œé€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰
            if os.getenv("ENABLE_SELF_CRITIQUE", "false").lower() == "true":
                article_type_result = detect_article_type(text, filename)
                original_label = result.label
                original_has_ae = result.has_ae
                original_has_causality = result.has_causality
                original_has_special = result.has_special_situation
                original_patient_mode = result.patient_mode
                result = critique_classification(result, text, article_type_result['type'], filename)

                # è¾“å‡ºä¿®æ­£ä¿¡æ¯
                corrections = []
                if result.has_ae != original_has_ae:
                    corrections.append(f"AE:{original_has_ae}â†’{result.has_ae}")
                if result.has_causality != original_has_causality:
                    corrections.append(f"å› æœ:{original_has_causality}â†’{result.has_causality}")
                if result.has_special_situation != original_has_special:
                    corrections.append(f"ç‰¹æ®Š:{original_has_special}â†’{result.has_special_situation}")
                if result.patient_mode != original_patient_mode:
                    corrections.append(f"æ‚£è€…:{original_patient_mode}â†’{result.patient_mode}")
                if corrections:
                    print(f"      ğŸ”„ Self-Critique [{', '.join(corrections)}]: {original_label} â†’ {result.label}")

        results.append(result)

        if result.error:
            print(f"      âŒ Error: {result.error}")
        else:
            print(f"      âœ… {result.label} ({result.label_cn})")
            print(f"         Confidence: {result.confidence:.2f}")
            flags = []
            if result.has_drug:
                flags.append("Drugâœ“")
            if result.has_ae:
                flags.append("AEâœ“")
            if result.has_causality:
                flags.append("Causalityâœ“")
            if result.has_special_situation:
                flags.append("Specialâœ“")
            print(f"         Flags: {' '.join(flags) or 'None'}")
            if result.needs_review:
                print("         âš ï¸ Needs human review")

    # Write results to CSV
    output_path.parent.mkdir(parents=True, exist_ok=True)

    fieldnames = [
        "filename", "label", "label_cn", "confidence", "needs_review",
        "has_drug", "has_ae", "has_causality", "has_special_situation",
        "patient_mode", "patient_max_n",
        "drug_evidence", "ae_evidence", "causality_evidence", "special_evidence", "patient_evidence",
        "has_drug_reasoning", "has_ae_reasoning", "has_causality_reasoning",
        "has_special_reasoning", "patient_reasoning",
        "reasoning", "extract_method", "text_length", "classify_time", "error"
    ]

    with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)
        writer.writeheader()
        for result in results:
            row = asdict(result)
            # Convert lists to strings
            for key in ["drug_evidence", "ae_evidence", "causality_evidence", "special_evidence", "patient_evidence"]:
                row[key] = "; ".join(row[key]) if row[key] else ""
            writer.writerow(row)

    # Summary
    print("\n" + "=" * 60)
    print("ğŸ“Š Classification Summary:")

    label_counts: dict[str, int] = {}
    error_count = 0
    review_count = 0
    for r in results:
        if r.error:
            error_count += 1
        else:
            label_counts[r.label] = label_counts.get(r.label, 0) + 1
            if r.needs_review:
                review_count += 1

    for label, count in sorted(label_counts.items(), key=lambda x: -x[1]):
        print(f"   {label}: {count}")

    if error_count:
        print(f"   Errors: {error_count}")
    if review_count:
        print(f"   âš ï¸ Needs review: {review_count}")

    print(f"\nğŸ“ Results saved to: {output_path}")
    print("=" * 60)

    return results


def main():
    parser = argparse.ArgumentParser(description="Wanfang Paper Safety Classification Script")
    parser.add_argument(
        "--input-dir", "-i",
        type=Path,
        default=PAPERS_DIR,
        help=f"Directory containing PDF files (default: {PAPERS_DIR})",
    )
    parser.add_argument(
        "--output", "-o",
        type=Path,
        default=DEFAULT_OUTPUT,
        help=f"Output CSV file path (default: {DEFAULT_OUTPUT})",
    )
    parser.add_argument(
        "--drugs", "-d",
        type=str,
        default="",
        help="Comma-separated drug keywords (e.g., 'æ›¿æ ¼ç‘æ´›,ticagrelor')",
    )
    parser.add_argument(
        "--drugs-file", "-f",
        type=Path,
        default=None,
        help="Path to drug keywords file (one per line)",
    )
    parser.add_argument(
        "--max-papers", "-m",
        type=int,
        default=0,
        help="Maximum papers to classify (0 = unlimited)",
    )

    args = parser.parse_args()

    # Load drug keywords
    drug_keywords = []
    if args.drugs:
        drug_keywords.extend([k.strip() for k in args.drugs.split(",") if k.strip()])
    if args.drugs_file:
        drug_keywords.extend(load_drug_keywords(args.drugs_file))

    # å¦‚æœæ²¡æœ‰æä¾›è¯ç‰©å…³é”®è¯ï¼Œå°è¯•åŠ è½½é»˜è®¤æ¸…å•
    if not drug_keywords and DEFAULT_DRUGS_FILE.exists():
        drug_keywords.extend(load_drug_keywords(DEFAULT_DRUGS_FILE))
        print(f"Loaded default drug keywords from: {DEFAULT_DRUGS_FILE}")

    if not drug_keywords:
        print("Warning: No drug keywords provided. Use --drugs or --drugs-file")

    # Validate input directory
    if not args.input_dir.exists():
        print(f"Error: Input directory not found: {args.input_dir}")
        return 1

    pdf_count = len(list(args.input_dir.glob("*.pdf")))
    if pdf_count == 0:
        print(f"Error: No PDF files found in {args.input_dir}")
        return 1

    print("=" * 60)
    print("ğŸ“š Wanfang Paper Safety Classification")
    print("=" * 60)
    print(f"Input: {args.input_dir}")
    print(f"Output: {args.output}")
    print(f"Drug keywords: {len(drug_keywords)}")
    if drug_keywords:
        print(f"   Examples: {', '.join(drug_keywords[:5])}")
    print(f"Max papers: {args.max_papers if args.max_papers > 0 else 'unlimited'}")
    print(f"Found {pdf_count} PDF files")
    print("=" * 60)

    results = classify_papers(
        input_dir=args.input_dir,
        output_path=args.output,
        drug_keywords=drug_keywords,
        max_papers=args.max_papers,
    )

    error_count = sum(1 for r in results if r.error)
    return 1 if error_count == len(results) else 0


if __name__ == "__main__":
    exit(main())
