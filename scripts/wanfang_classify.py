#!/usr/bin/env python3
"""Wanfang Medical Paper Safety Classification Script.

This script classifies downloaded papers from Wanfang Medical database
using LLM (OpenAI GPT) for pharmacovigilance/drug safety classification.

æ–‡çŒ®æ£€ç´¢ä¸šåŠ¡åŸºç¡€æµç¨‹ï¼š
åœ¨å…¨æ–‡èŒƒå›´å†…ä»¥ä¸­è‹±æ–‡å•†å“å&æ´»æ€§æˆåˆ†åä½œä¸ºå…³é”®è¯è¿›è¡Œæ£€ç´¢ï¼Œæ£€ç´¢å‡ºæœ¬å‘¨æœŸå†…ä¸ŠæŠ›åˆ°
CNKI & Wanfangæ•°æ®åº“ä¸­çš„æ–‡çŒ®ã€‚é’ˆå¯¹æ‰€æœ‰æ£€ç´¢å‡ºæ¥çš„æ–‡çŒ®è¿›è¡Œäººå·¥å®¡é˜…ï¼Œè¯†åˆ«æ–‡ç« ä¸­
æ˜¯å¦æåŠä»»ä½•è¯ºåè¯ç›¸å…³å®‰å…¨ç—…ä¾‹æˆ–æ½œåœ¨ä¿¡å·ã€‚

Classification categories (è¯ç‰©å®‰å…¨åˆ†ç±»):
- Rejection: æ–‡ç« ä¸­ç¼ºå°‘drug(è¯ºåè¯)æˆ–AE(ä¸è‰¯äº‹ä»¶)ä»»æ„ä¸€ä¸ªè¦ç´ 
- ICSR: (drug+AE+å› æœå…³ç³»+å•ä¸ªæ‚£è€…) OR (drug+ç‰¹æ®Šæƒ…å†µ+å•ä¸ªæ‚£è€…)
- Multiple_Patients: (drug+AE+å› æœå…³ç³»+å¤šä¸ªæ‚£è€…) OR (drug+ç‰¹æ®Šæƒ…å†µ+å¤šä¸ªæ‚£è€…)
- ICSR+Multiple_Patients: ä¸€ç¯‡æ–‡ç« åŒæ—¶æ»¡è¶³ICSRå’ŒMultiple_Patientsçš„æ¡ä»¶
- Other_Safety_Signal: ä¸ç¬¦åˆä¸Šé¢ç±»å‹çš„éƒ½åˆç­›æˆsignal

Usage:
    # Classify all papers in data/papers/
    python scripts/wanfang_classify.py --drugs "æ›¿æ ¼ç‘æ´›,ticagrelor"

    # With drug keywords file
    python scripts/wanfang_classify.py --drugs-file data/drug_keywords.txt

    # Specify custom directory
    python scripts/wanfang_classify.py --input-dir data/papers --drugs "è¯ç‰©å"
"""

import argparse
import csv
import json
import os
import subprocess
import tempfile
from dataclasses import dataclass, field, asdict
from datetime import datetime
from pathlib import Path
from typing import Any

from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables
load_dotenv()

# Directories
DATA_DIR = Path(__file__).parent.parent / "data"
PAPERS_DIR = DATA_DIR / "papers"
DEFAULT_OUTPUT = DATA_DIR / "classification_results.csv"


# Classification labels
SAFETY_LABELS = {
    "Rejection": "æ‹’ç» (ç¼ºå°‘è¯ç‰©æˆ–AE)",
    "ICSR": "ä¸ªä¾‹å®‰å…¨æŠ¥å‘Š (å•æ‚£è€…)",
    "Multiple_Patients": "å¤šæ‚£è€…æŠ¥å‘Š (>1ä¾‹)",
    "ICSR+Multiple_Patients": "æ··åˆæŠ¥å‘Š (åŒæ—¶æœ‰å•æ‚£è€…å’Œå¤šæ‚£è€…)",
    "Other_Safety_Signal": "å…¶ä»–å®‰å…¨ä¿¡å· (åˆç­›)",
}

PATIENT_MODES = {"single", "multiple", "mixed", "unknown"}


@dataclass
class PatientInfo:
    mode: str  # single / multiple / mixed / unknown
    max_n: int | None
    evidence: list[str]


@dataclass
class ClassificationResult:
    filename: str
    label: str
    label_cn: str
    has_drug: bool
    has_ae: bool
    has_causality: bool
    has_special_situation: bool
    patient_mode: str
    patient_max_n: int | None
    confidence: float
    drug_evidence: list[str]
    ae_evidence: list[str]
    causality_evidence: list[str]
    special_evidence: list[str]
    patient_evidence: list[str]
    reasoning: str
    needs_review: bool
    extract_method: str
    text_length: int
    classify_time: str = field(default_factory=lambda: datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    error: str = ""


def which(cmd: str) -> str | None:
    """Find executable in PATH."""
    import shutil
    return shutil.which(cmd)


def extract_pdf_text(pdf_path: Path, max_pages: int = 30) -> tuple[str, str]:
    """Extract text from PDF using pdftotext or pymupdf."""
    # Try pdftotext first
    pdftotext = which("pdftotext")
    if pdftotext:
        try:
            with tempfile.TemporaryDirectory() as tmpdir:
                out_path = Path(tmpdir) / "out.txt"
                proc = subprocess.run(
                    [pdftotext, "-layout", "-enc", "UTF-8", "-l", str(max_pages), str(pdf_path), str(out_path)],
                    capture_output=True,
                    text=True,
                    timeout=60,
                )
                if proc.returncode == 0 and out_path.exists():
                    text = out_path.read_text(encoding="utf-8", errors="ignore")
                    if len(text.strip()) >= 50:
                        return text, "pdftotext"
        except Exception:
            pass

    # Fallback to pymupdf
    try:
        import fitz
        doc = fitz.open(str(pdf_path))
        texts = []
        for i, page in enumerate(doc):
            if i >= max_pages:
                break
            texts.append(page.get_text())
        doc.close()
        text = "\n\n".join(texts)
        if text.strip():
            return text, "pymupdf"
    except ImportError:
        pass
    except Exception:
        pass

    return "", "none"


def truncate_text(text: str, max_chars: int = 45000) -> str:
    """Truncate text to max characters, keeping head and tail."""
    if len(text) <= max_chars:
        return text
    head = int(max_chars * 0.7)
    tail = max_chars - head
    return text[:head] + "\n\n[...truncated...]\n\n" + text[-tail:]


def classify_by_rules(
    has_drug: bool,
    has_ae: bool,
    has_causality: bool,
    has_special_situation: bool,
    patient_mode: str,
) -> str:
    """Rule-based classification logic.

    åˆ†ç±»åˆ¤æ–­é€»è¾‘ï¼š
    1. Rejectionï¼šæ–‡ç« ä¸­ç¼ºå°‘drug(è¯ºåè¯)æˆ–AE(ä¸è‰¯äº‹ä»¶)ä»»æ„ä¸€ä¸ªè¦ç´ 
    2. ICSRï¼š(drug+AE+å› æœå…³ç³»+å•ä¸ªæ‚£è€…) OR (drug+ç‰¹æ®Šæƒ…å†µ+å•ä¸ªæ‚£è€…)
    3. Multiple_Patientsï¼š(drug+AE+å› æœå…³ç³»+å¤šä¸ªæ‚£è€…) OR (drug+ç‰¹æ®Šæƒ…å†µ+å¤šä¸ªæ‚£è€…)
    4. ICSR+Multiple_Patientsï¼šä¸€ç¯‡æ–‡ç« åŒæ—¶æ»¡è¶³ICSRå’ŒMultiple_Patientsçš„æ¡ä»¶
    5. Other_Safety_Signalï¼šä¸ç¬¦åˆä¸Šé¢ç±»å‹çš„éƒ½åˆç­›æˆsignal
    """
    # Rejection: ç¼ºå°‘ drug æˆ– AE ä»»æ„ä¸€ä¸ªè¦ç´ 
    if not has_drug or not has_ae:
        return "Rejection"

    # æ»¡è¶³ICSR/Multiple_Patientsçš„æ¡ä»¶ï¼š
    # - (AE + å› æœå…³ç³») OR ç‰¹æ®Šæƒ…å†µ
    meets_criteria = (has_ae and has_causality) or has_special_situation

    if patient_mode == "single":
        # å•ä¸ªæ‚£è€…ï¼šæ»¡è¶³æ¡ä»¶åˆ™ICSRï¼Œå¦åˆ™Other_Safety_Signal
        return "ICSR" if meets_criteria else "Other_Safety_Signal"

    if patient_mode == "multiple":
        # å¤šä¸ªæ‚£è€…(>1ä¾‹)ï¼šæ»¡è¶³æ¡ä»¶åˆ™Multiple_Patientsï¼Œå¦åˆ™Other_Safety_Signal
        return "Multiple_Patients" if meets_criteria else "Other_Safety_Signal"

    if patient_mode == "mixed":
        # æ··åˆ(åŒæ—¶æœ‰å•æ‚£è€…å’Œå¤šæ‚£è€…æè¿°)ï¼šæ»¡è¶³æ¡ä»¶åˆ™ICSR+Multiple_Patients
        return "ICSR+Multiple_Patients" if meets_criteria else "Other_Safety_Signal"

    # å…¶ä»–æƒ…å†µï¼ˆunknownç­‰ï¼‰éƒ½åˆç­›æˆsignal
    return "Other_Safety_Signal"


def classify_with_openai(text: str, filename: str, drug_keywords: list[str]) -> ClassificationResult:
    """Classify paper using OpenAI GPT for drug safety."""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return ClassificationResult(
            filename=filename, label="Error", label_cn="é”™è¯¯",
            has_drug=False, has_ae=False, has_causality=False, has_special_situation=False,
            patient_mode="unknown", patient_max_n=None, confidence=0.0,
            drug_evidence=[], ae_evidence=[], causality_evidence=[],
            special_evidence=[], patient_evidence=[], reasoning="",
            needs_review=True, extract_method="", text_length=0,
            error="OPENAI_API_KEY not set"
        )

    client = OpenAI(api_key=api_key)
    drug_hint = ", ".join(drug_keywords[:100]) if drug_keywords else "(æœªæä¾›è¯ç‰©å…³é”®è¯)"

    system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è¯ç‰©è­¦æˆ’ä¿¡æ¯æå–ä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä»åŒ»å­¦/ç§‘å­¦æ–‡çŒ®ä¸­æå–å…³é”®å®‰å…¨ä¿¡æ¯ï¼Œç”¨äºè¯ºåè¯ç‰©å®‰å…¨ç›‘æµ‹ã€‚

æ–‡çŒ®æ£€ç´¢ä¸šåŠ¡èƒŒæ™¯ï¼š
åœ¨å…¨æ–‡èŒƒå›´å†…ä»¥ä¸­è‹±æ–‡å•†å“å&æ´»æ€§æˆåˆ†åä½œä¸ºå…³é”®è¯è¿›è¡Œæ£€ç´¢ï¼Œæ£€ç´¢å‡ºä¸ŠæŠ›åˆ°CNKI & Wanfangæ•°æ®åº“ä¸­çš„æ–‡çŒ®ã€‚
é’ˆå¯¹æ‰€æœ‰æ£€ç´¢å‡ºæ¥çš„æ–‡çŒ®è¿›è¡Œå®¡é˜…ï¼Œè¯†åˆ«æ–‡ç« ä¸­æ˜¯å¦æåŠä»»ä½•è¯ºåè¯ç›¸å…³å®‰å…¨ç—…ä¾‹æˆ–æ½œåœ¨ä¿¡å·ã€‚

åˆ†ç±»åˆ¤æ–­é€»è¾‘ï¼š
1. Rejectionï¼šæ–‡ç« ä¸­ç¼ºå°‘drug(è¯ºåè¯)æˆ–AE(ä¸è‰¯äº‹ä»¶)ä»»æ„ä¸€ä¸ªè¦ç´ 
2. ICSRï¼š(drug+AE+å› æœå…³ç³»+å•ä¸ªæ‚£è€…) OR (drug+ç‰¹æ®Šæƒ…å†µ+å•ä¸ªæ‚£è€…)
3. Multiple_Patientsï¼š(drug+AE+å› æœå…³ç³»+å¤šä¸ªæ‚£è€…) OR (drug+ç‰¹æ®Šæƒ…å†µ+å¤šä¸ªæ‚£è€…)
4. ICSR+Multiple_Patientsï¼šä¸€ç¯‡æ–‡ç« åŒæ—¶æ»¡è¶³ICSRå’ŒMultiple_Patientsçš„æ¡ä»¶
5. Other_Safety_Signalï¼šä¸ç¬¦åˆä¸Šé¢ç±»å‹çš„éƒ½åˆç­›æˆsignal

éœ€è¦æå–çš„å­—æ®µï¼š

1. **has_drug** (boolean): æ–‡ç« æ˜¯å¦æåŠç›®æ ‡è¯ºåè¯ç‰©ï¼Ÿ
   - ä½¿ç”¨æä¾›çš„è¯ç‰©å…³é”®è¯åˆ—è¡¨ï¼ˆä¸­è‹±æ–‡å•†å“åã€æ´»æ€§æˆåˆ†åï¼‰ä½œä¸ºå‚è€ƒ
   - æ³¨æ„ï¼šPDFæ–‡ä»¶åå‰ç¼€é€šå¸¸åŒ…å«å¯¹åº”çš„è¯ºåäº§å“å

2. **has_ae** (boolean): æ˜¯å¦æè¿°äº†ä»»ä½•ä¸è‰¯äº‹ä»¶(AE)ï¼Ÿ
   - å‰¯ä½œç”¨ã€æ¯’æ€§ååº”ã€ä¸è‰¯ååº”ã€å®‰å…¨äº‹ä»¶
   - ä»»ä½•å¯èƒ½ä¸è¯ç‰©ä½¿ç”¨ç›¸å…³çš„è´Ÿé¢å¥åº·ç»“æœ

3. **has_causality** (boolean): æ˜¯å¦æœ‰æ˜ç¡®çš„å› æœå…³ç³»è¡¨è¿°å°†è¯ç‰©ä¸äº‹ä»¶è”ç³»èµ·æ¥ï¼Ÿ
   - YES: "ä¸...ç›¸å…³"ã€"ç”±...å¼•èµ·"ã€"å½’å› äº"ã€"è¯ç‰©è¯±å‘"ã€"æ²»ç–—ç›¸å…³"
   - YES: "æ€€ç–‘ä¸...ç›¸å…³"ã€é˜³æ€§å†æ¿€å‘/å»æ¿€å‘è¯•éªŒ
   - NO: ä»…æœ‰æ—¶é—´å…³è”è€Œæ— å½’å› 
   - NO: å¦å®šé™ˆè¿°ï¼ˆ"ä¸...æ— å…³"ã€"ä¸ç›¸å…³"ï¼‰
   - NO: ä»…æœ‰äººç¾¤ç»Ÿè®¡æ•°æ®è€Œæ— ä¸ªä½“å½’å› 

4. **has_special_situation** (boolean): æ˜¯å¦å­˜åœ¨ä»¥ä¸‹ç‰¹æ®Šæƒ…å†µï¼Ÿ
   - å¦Šå¨ /å“ºä¹³æœŸæš´éœ² (Pregnancy/lactation exposure)
   - å„¿ç«¥ç”¨è¯ (Pediatric use - children, infants)
   - è¯ç‰©æ— æ•ˆ/ç–—æ•ˆä¸ä½³ (Lack of efficacy/therapeutic failure)
   - è¿‡é‡ (Overdose)
   - ç”¨è¯é”™è¯¯ (Medication error)
   - è¯ç‰©ç›¸äº’ä½œç”¨ (Drug-drug interaction)
   - è¶…è¯´æ˜ä¹¦ç”¨è¯ (Off-label use)

5. **patient_mode** (string): æ‚£è€…è¯†åˆ«
   - "single": å•ä¸ªå¯è¯†åˆ«æ‚£è€… (n=1, ç—…ä¾‹æŠ¥å‘Š, æœ‰å¹´é¾„/æ€§åˆ«å¯åˆ¤æ–­å•ä¸€æ‚£è€…å­˜åœ¨, æˆ–æ–‡ç« æåˆ°"1ä¾‹")
   - "multiple": å¤šä¸ªæ‚£è€… (n>1, ä½œä¸ºé˜Ÿåˆ—æè¿°)
   - "mixed": æ–‡ç« ä¸­åŒæ—¶å­˜åœ¨å•æ‚£è€…éƒ¨åˆ†å’Œå¤šæ‚£è€…éƒ¨åˆ†
   - "unknown": æ— æ˜ç¡®æ‚£è€…ä¿¡æ¯æˆ–ä»…æœ‰æ±‡æ€»ç»Ÿè®¡æ•°æ®

ä»…è¿”å›åŒ…å«è¿™äº›å­—æ®µå’Œè¯æ®æ•°ç»„çš„JSONå¯¹è±¡ã€‚"""

    user_prompt = f"""ç›®æ ‡è¯ºåè¯ç‰©å…³é”®è¯ï¼ˆä¸­è‹±æ–‡å•†å“å & æ´»æ€§æˆåˆ†åï¼‰:
{drug_hint}

æå–æ­¥éª¤:
1. ä»”ç»†é˜…è¯»æ–‡ç« å…¨æ–‡
2. è¯†åˆ«æ˜¯å¦æåˆ°ç›®æ ‡è¯ºåè¯ç‰©ï¼ˆæ³¨æ„ï¼šPDFå‰ç¼€é€šå¸¸åŒ…å«å¯¹åº”äº§å“åï¼‰
3. æŸ¥æ‰¾æ˜¯å¦æè¿°äº†ä¸è‰¯äº‹ä»¶(AE)
4. æŸ¥æ‰¾æ˜¯å¦æœ‰æ˜ç¡®çš„å› æœå…³ç³»è¡¨è¿°ï¼ˆ"ä¸è¯ç‰©ç›¸å…³"ã€"è¯ç‰©å¼•èµ·"ç­‰ï¼‰
5. æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç‰¹æ®Šæƒ…å†µï¼ˆå„¿ç«¥ç”¨è¯ã€è¯ç‰©æ— æ•ˆã€æ€€å­•æš´éœ²ç­‰ï¼‰
6. åˆ¤æ–­æ‚£è€…æ•°é‡:
   - single: å•ä¸ªæ‚£è€…ï¼ˆå¹´é¾„æ€§åˆ«å¯åˆ¤æ–­å•ä¸€æ‚£è€…å­˜åœ¨ï¼Œæˆ–æ–‡ç« æåˆ°"1ä¾‹"ï¼‰
   - multiple: å¤šä¸ªæ‚£è€…ï¼ˆ>1ä¾‹ï¼‰
   - mixed: åŒæ—¶æœ‰å•æ‚£è€…å’Œå¤šæ‚£è€…æè¿°
   - unknown: æ— æ˜ç¡®æ‚£è€…ä¿¡æ¯

åˆ†ç±»é€»è¾‘è¯´æ˜:
- Rejection: ç¼ºå°‘drugæˆ–AEä»»æ„ä¸€ä¸ªè¦ç´ 
- ICSR: (drug+AE+å› æœå…³ç³»+å•æ‚£è€…) OR (drug+ç‰¹æ®Šæƒ…å†µ+å•æ‚£è€…)
- Multiple_Patients: (drug+AE+å› æœå…³ç³»+å¤šæ‚£è€…) OR (drug+ç‰¹æ®Šæƒ…å†µ+å¤šæ‚£è€…)
- ICSR+Multiple_Patients: åŒæ—¶æ»¡è¶³ICSRå’ŒMultiple_Patients
- Other_Safety_Signal: å…¶ä»–æƒ…å†µåˆç­›ä¸ºsignal

ç½®ä¿¡åº¦è¯„åˆ†:
0.90-1.0: æ‰€æœ‰å­—æ®µéƒ½æœ‰æ˜ç¡®è¯æ®
0.75-0.89: ä¸»è¦å­—æ®µæ¸…æ™°
0.60-0.74: éƒ¨åˆ†å­—æ®µæ¨¡ç³Š
<0.60: è¯æ®ä¸è¶³

æ–‡ç« å†…å®¹:
---
{truncate_text(text)}
---

è¿”å›JSONæ ¼å¼:
{{
  "has_drug": boolean,
  "has_ae": boolean,
  "has_causality": boolean,
  "has_special_situation": boolean,
  "patient_mode": "single|multiple|mixed|unknown",
  "patient_max_n": integer or null,
  "confidence": 0.0-1.0,
  "reasoning": "ç®€è¦è¯´æ˜åˆ†æè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ä¸ºä½•åˆ¤å®šä¸ºæŸä¸ªåˆ†ç±»",
  "evidence": {{
    "drug": ["åŸæ–‡ä¸­æåŠè¯ç‰©çš„è¯æ®"],
    "ae": ["åŸæ–‡ä¸­ä¸è‰¯äº‹ä»¶çš„æè¿°"],
    "causality": ["åŸæ–‡ä¸­å› æœå…³ç³»çš„è¡¨è¿°"],
    "special_situation": ["åŸæ–‡ä¸­ç‰¹æ®Šæƒ…å†µçš„æè¿°"],
    "patient": ["åŸæ–‡ä¸­æ‚£è€…ä¿¡æ¯çš„æè¿°ï¼ŒåŒ…æ‹¬æ•°é‡åˆ¤æ–­ä¾æ®"]
  }}
}}"""

    try:
        # ä½¿ç”¨ä¸“é—¨çš„åˆ†ç±»æ¨¡å‹é…ç½®ï¼Œé»˜è®¤ gpt-4o
        model = os.getenv("CLASSIFY_MODEL_NAME", "gpt-4o")
        # o1/o3 models don't support temperature parameter
        is_reasoning_model = model.startswith("o1") or model.startswith("o3")

        create_kwargs = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
        }

        # Only set temperature for non-reasoning models
        if not is_reasoning_model:
            create_kwargs["temperature"] = 0
            create_kwargs["response_format"] = {"type": "json_object"}

        response = client.chat.completions.create(**create_kwargs)

        content = response.choices[0].message.content or "{}"
        obj = json.loads(content)

        # Extract fields
        has_drug = bool(obj.get("has_drug", False))
        has_ae = bool(obj.get("has_ae", False))
        has_causality = bool(obj.get("has_causality", False))
        has_special = bool(obj.get("has_special_situation", False))

        patient_mode = str(obj.get("patient_mode", "unknown")).lower()
        if patient_mode not in PATIENT_MODES:
            patient_mode = "unknown"

        patient_max_n = obj.get("patient_max_n")
        if patient_max_n is not None:
            try:
                patient_max_n = int(patient_max_n)
            except (ValueError, TypeError):
                patient_max_n = None

        confidence = float(obj.get("confidence", 0.5))
        confidence = max(0.0, min(1.0, confidence))

        # Apply rule-based classification
        label = classify_by_rules(has_drug, has_ae, has_causality, has_special, patient_mode)

        # Extract evidence
        evidence = obj.get("evidence", {}) or {}
        drug_evidence = evidence.get("drug", []) or []
        ae_evidence = evidence.get("ae", []) or []
        causality_evidence = evidence.get("causality", []) or []
        special_evidence = evidence.get("special_situation", []) or []
        patient_evidence = evidence.get("patient", []) or []

        return ClassificationResult(
            filename=filename,
            label=label,
            label_cn=SAFETY_LABELS.get(label, "æœªçŸ¥"),
            has_drug=has_drug,
            has_ae=has_ae,
            has_causality=has_causality,
            has_special_situation=has_special,
            patient_mode=patient_mode,
            patient_max_n=patient_max_n,
            confidence=confidence,
            drug_evidence=drug_evidence[:5],
            ae_evidence=ae_evidence[:5],
            causality_evidence=causality_evidence[:5],
            special_evidence=special_evidence[:5],
            patient_evidence=patient_evidence[:5],
            reasoning=obj.get("reasoning", ""),
            needs_review=confidence < 0.65,
            extract_method="",
            text_length=len(text),
        )

    except json.JSONDecodeError as e:
        return ClassificationResult(
            filename=filename, label="Error", label_cn="é”™è¯¯",
            has_drug=False, has_ae=False, has_causality=False, has_special_situation=False,
            patient_mode="unknown", patient_max_n=None, confidence=0.0,
            drug_evidence=[], ae_evidence=[], causality_evidence=[],
            special_evidence=[], patient_evidence=[], reasoning="",
            needs_review=True, extract_method="", text_length=len(text),
            error=f"JSON parse error: {e}"
        )
    except Exception as e:
        return ClassificationResult(
            filename=filename, label="Error", label_cn="é”™è¯¯",
            has_drug=False, has_ae=False, has_causality=False, has_special_situation=False,
            patient_mode="unknown", patient_max_n=None, confidence=0.0,
            drug_evidence=[], ae_evidence=[], causality_evidence=[],
            special_evidence=[], patient_evidence=[], reasoning="",
            needs_review=True, extract_method="", text_length=len(text),
            error=str(e)
        )


def load_drug_keywords(path: Path) -> list[str]:
    """Load drug keywords from file."""
    if not path.exists():
        return []
    keywords = []
    for line in path.read_text(encoding="utf-8", errors="ignore").splitlines():
        line = line.strip()
        if line and not line.startswith("#"):
            keywords.append(line)
    return keywords


def classify_papers(
    input_dir: Path,
    output_path: Path,
    drug_keywords: list[str],
    max_papers: int = 0,
) -> list[ClassificationResult]:
    """Classify all papers in input directory."""
    pdf_files = sorted(input_dir.glob("*.pdf"))
    total = len(pdf_files)

    if max_papers > 0:
        pdf_files = pdf_files[:max_papers]

    print(f"\nğŸ“š Classifying {len(pdf_files)} papers (from {total} total)")
    print(f"   Drug keywords: {len(drug_keywords)}")
    print("=" * 60)

    results: list[ClassificationResult] = []

    for idx, pdf_path in enumerate(pdf_files, 1):
        filename = pdf_path.name
        print(f"\n[{idx}/{len(pdf_files)}] ğŸ“„ {filename[:50]}...")

        # Extract text
        print("      Extracting text...")
        text, method = extract_pdf_text(pdf_path)

        if not text.strip():
            print("      âŒ Could not extract text")
            results.append(ClassificationResult(
                filename=filename, label="Error", label_cn="é”™è¯¯",
                has_drug=False, has_ae=False, has_causality=False, has_special_situation=False,
                patient_mode="unknown", patient_max_n=None, confidence=0.0,
                drug_evidence=[], ae_evidence=[], causality_evidence=[],
                special_evidence=[], patient_evidence=[], reasoning="",
                needs_review=True, extract_method=method, text_length=0,
                error="Text extraction failed"
            ))
            continue

        print(f"      Extracted {len(text)} chars via {method}")

        # Classify
        print("      Classifying with LLM...")
        result = classify_with_openai(text, filename, drug_keywords)
        result.extract_method = method
        results.append(result)

        if result.error:
            print(f"      âŒ Error: {result.error}")
        else:
            print(f"      âœ… {result.label} ({result.label_cn})")
            print(f"         Confidence: {result.confidence:.2f}")
            flags = []
            if result.has_drug:
                flags.append("Drugâœ“")
            if result.has_ae:
                flags.append("AEâœ“")
            if result.has_causality:
                flags.append("Causalityâœ“")
            if result.has_special_situation:
                flags.append("Specialâœ“")
            print(f"         Flags: {' '.join(flags) or 'None'}")
            if result.needs_review:
                print("         âš ï¸ Needs human review")

    # Write results to CSV
    output_path.parent.mkdir(parents=True, exist_ok=True)

    fieldnames = [
        "filename", "label", "label_cn", "confidence", "needs_review",
        "has_drug", "has_ae", "has_causality", "has_special_situation",
        "patient_mode", "patient_max_n",
        "drug_evidence", "ae_evidence", "causality_evidence", "special_evidence", "patient_evidence",
        "reasoning", "extract_method", "text_length", "classify_time", "error"
    ]

    with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)
        writer.writeheader()
        for result in results:
            row = asdict(result)
            # Convert lists to strings
            for key in ["drug_evidence", "ae_evidence", "causality_evidence", "special_evidence", "patient_evidence"]:
                row[key] = "; ".join(row[key]) if row[key] else ""
            writer.writerow(row)

    # Summary
    print("\n" + "=" * 60)
    print("ğŸ“Š Classification Summary:")

    label_counts: dict[str, int] = {}
    error_count = 0
    review_count = 0
    for r in results:
        if r.error:
            error_count += 1
        else:
            label_counts[r.label] = label_counts.get(r.label, 0) + 1
            if r.needs_review:
                review_count += 1

    for label, count in sorted(label_counts.items(), key=lambda x: -x[1]):
        print(f"   {label}: {count}")

    if error_count:
        print(f"   Errors: {error_count}")
    if review_count:
        print(f"   âš ï¸ Needs review: {review_count}")

    print(f"\nğŸ“ Results saved to: {output_path}")
    print("=" * 60)

    return results


def main():
    parser = argparse.ArgumentParser(description="Wanfang Paper Safety Classification Script")
    parser.add_argument(
        "--input-dir", "-i",
        type=Path,
        default=PAPERS_DIR,
        help=f"Directory containing PDF files (default: {PAPERS_DIR})",
    )
    parser.add_argument(
        "--output", "-o",
        type=Path,
        default=DEFAULT_OUTPUT,
        help=f"Output CSV file path (default: {DEFAULT_OUTPUT})",
    )
    parser.add_argument(
        "--drugs", "-d",
        type=str,
        default="",
        help="Comma-separated drug keywords (e.g., 'æ›¿æ ¼ç‘æ´›,ticagrelor')",
    )
    parser.add_argument(
        "--drugs-file", "-f",
        type=Path,
        default=None,
        help="Path to drug keywords file (one per line)",
    )
    parser.add_argument(
        "--max-papers", "-m",
        type=int,
        default=0,
        help="Maximum papers to classify (0 = unlimited)",
    )

    args = parser.parse_args()

    # Load drug keywords
    drug_keywords = []
    if args.drugs:
        drug_keywords.extend([k.strip() for k in args.drugs.split(",") if k.strip()])
    if args.drugs_file:
        drug_keywords.extend(load_drug_keywords(args.drugs_file))

    if not drug_keywords:
        print("Warning: No drug keywords provided. Use --drugs or --drugs-file")

    # Validate input directory
    if not args.input_dir.exists():
        print(f"Error: Input directory not found: {args.input_dir}")
        return 1

    pdf_count = len(list(args.input_dir.glob("*.pdf")))
    if pdf_count == 0:
        print(f"Error: No PDF files found in {args.input_dir}")
        return 1

    print("=" * 60)
    print("ğŸ“š Wanfang Paper Safety Classification")
    print("=" * 60)
    print(f"Input: {args.input_dir}")
    print(f"Output: {args.output}")
    print(f"Drug keywords: {len(drug_keywords)}")
    if drug_keywords:
        print(f"   Examples: {', '.join(drug_keywords[:5])}")
    print(f"Max papers: {args.max_papers if args.max_papers > 0 else 'unlimited'}")
    print(f"Found {pdf_count} PDF files")
    print("=" * 60)

    results = classify_papers(
        input_dir=args.input_dir,
        output_path=args.output,
        drug_keywords=drug_keywords,
        max_papers=args.max_papers,
    )

    error_count = sum(1 for r in results if r.error)
    return 1 if error_count == len(results) else 0


if __name__ == "__main__":
    exit(main())
